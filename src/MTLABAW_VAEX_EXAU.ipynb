{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47a69e2",
   "metadata": {},
   "source": [
    "# useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ad3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose data type:\n",
      "0 - cropped, 1 - cropped_aligned\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('choose data type:\\n0 - cropped, 1 - cropped_aligned')\n",
    "choice = int(input())\n",
    "if choice not in [0, 1]:\n",
    "    print('error... value out of bounds...')\n",
    "else:\n",
    "    if not choice:\n",
    "        data_root = './cropped_data/cropped'\n",
    "        data_type = 'cropped'\n",
    "    else:\n",
    "        data_root = './cropped-aligned_data/cropped_aligned'\n",
    "        data_type = 'cropped-aligned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7519f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!path \"./new_weights/cropped-aligned/batch=1024, logits=True/\" is already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_annotation_file = r'./annotations/training_set_annotations.txt'\n",
    "val_annotation_file = r'./annotations/validation_set_annotations.txt'\n",
    "model_path = r'./models/efficientnet_affectnet.pt'\n",
    "logits = True\n",
    "batch_size = 1024\n",
    "weights_dir = f'./new_weights/{data_type}/batch={batch_size}, logits={logits}/'\n",
    "\n",
    "if os.path.exists(weights_dir):\n",
    "    print(f'!path \"{weights_dir}\" is already exists')\n",
    "    pass\n",
    "else:\n",
    "    print(f'!path \"{weights_dir}\" was created')\n",
    "    os.mkdir(weights_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460ee4f",
   "metadata": {},
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a26b6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.nn.functional as F\n",
    "from timm.loss import AsymmetricLossSingleLabel\n",
    "import facenet_pytorch\n",
    "from facenet_pytorch import MTCNN\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "from torchmetrics import HingeLoss, F1Score\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import sklearn\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3705bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected device is cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Connected device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbf3dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(1996)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9000d",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06e713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolvedSignMomentumOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr=1e-4, betas=(.9, .99), weight_decay=.0):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError('Invalid learning rate: {}'.format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError('Invalid beta parameter at index 0: {}'.format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError('Invalid beta parameter at index 1: {}'.format(betas[1]))\n",
    "        \n",
    "        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "            # Perform stepweight decay\n",
    "            p.data.mul_(1 - group['lr'] * group['weight_decay'])\n",
    "\n",
    "            grad = p.grad\n",
    "            state = self.state[p]\n",
    "            # State initialization\n",
    "            if len(state) == 0:\n",
    "              # Exponential moving average of gradient values\n",
    "              state['exp_avg'] = torch.zeros_like(p)\n",
    "\n",
    "            exp_avg = state['exp_avg']\n",
    "            beta1, beta2 = group['betas']\n",
    "\n",
    "            # Weight update\n",
    "            update = exp_avg * beta1 + grad * (1 - beta1)\n",
    "            p.add_(torch.sign(update), alpha=-group['lr'])\n",
    "            # Decay the momentum running average coefficient\n",
    "            exp_avg.mul_(beta2).add_(grad, alpha=1 - beta2)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537cce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_CCC(prediction, ground_truth):\n",
    "    assert len(prediction) == len(ground_truth)\n",
    "    \n",
    "    eps = 1e-8\n",
    "    \n",
    "    n_objects = len(prediction)\n",
    "    ground_truth = ground_truth.view(-1)\n",
    "    prediction = prediction.view(-1)\n",
    "\n",
    "    prediction_mean = torch.sum(prediction) / n_objects\n",
    "    ground_truth_mean = torch.sum(ground_truth) / n_objects\n",
    "\n",
    "    prediction_var = (prediction - prediction_mean)\n",
    "    ground_truth_var = (ground_truth - ground_truth_mean)\n",
    "    \n",
    "    numerator = 2*torch.dot(prediction_var, ground_truth_var)\n",
    "    denominator = (torch.dot(prediction_var, prediction_var) + torch.dot(ground_truth_var, ground_truth_var) + torch.pow(prediction_mean - ground_truth_mean, 2) + eps)\n",
    "\n",
    "    ccc = numerator / denominator\n",
    "    \n",
    "    return ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10ee415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(prediction, ground_truth, task):\n",
    "    if task == 'VA':\n",
    "        CCC_va = compute_CCC(prediction[:, 0].to(device), ground_truth[:, 0].to(device))\n",
    "        CCC_ar = compute_CCC(prediction[:, 1].to(device), ground_truth[:, 1].to(device))   \n",
    "        \n",
    "        competition_part = 0.5 * (CCC_va + CCC_ar)\n",
    "    elif task == 'EX':\n",
    "        ground_truth = ground_truth.clone().cpu().detach().numpy()\n",
    "        prediction = prediction.clone().cpu().detach().numpy()\n",
    "        \n",
    "        competition_part = f1_score(ground_truth, prediction, average='macro')\n",
    "    elif task == 'AU':\n",
    "        ground_truth = ground_truth.clone().cpu().detach().numpy()\n",
    "        prediction = prediction.clone().cpu().detach().numpy()\n",
    "        \n",
    "        all_F1 = []\n",
    "        for t in range(12):\n",
    "            ground_truth_ = ground_truth[:, t]\n",
    "            prediction_ = prediction[:, t]\n",
    "            all_F1.append(f1_score(ground_truth_, prediction_, zero_division=0))\n",
    "\n",
    "        competition_part = np.mean(all_F1)\n",
    "\n",
    "    return competition_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd203c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABAWCCCLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ABAWCCCLoss, self).__init__()\n",
    "        self.eps = 1e-8\n",
    "\n",
    "    def forward(self, prediction, ground_truth):\n",
    "        assert len(prediction) == len(ground_truth)\n",
    "        \n",
    "        prediction_va, prediction_ar = prediction[:, 0], prediction[:, 1]\n",
    "        ground_truth_va, ground_truth_ar = ground_truth[:, 0], ground_truth[:, 1]\n",
    "        \n",
    "        CCC_va = compute_CCC(prediction_va, ground_truth_va)\n",
    "        CCC_ar = compute_CCC(prediction_ar, ground_truth_ar)\n",
    "        \n",
    "        loss = 1 - 0.5 * (CCC_va + CCC_ar)\n",
    "        loss.requires_grad_ = True\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcfe152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABAWMTLLoss(nn.Module):\n",
    "    def __init__(self, expression_weights, action_unit_weights):\n",
    "        super(ABAWMTLLoss, self).__init__()\n",
    "        self.va_criterion = ABAWCCCLoss()\n",
    "        self.ex_criterion = nn.CrossEntropyLoss(weight=expression_weights)\n",
    "        self.au_criterion = nn.BCEWithLogitsLoss(pos_weight=action_unit_weights.reshape(-1, 12))\n",
    "        \n",
    "    def forward(self, prediction, ground_truth):\n",
    "        assert len(prediction) == len(ground_truth)\n",
    "        va_input, ex_input, au_input = ground_truth[:, :2].to(device), \\\n",
    "            ground_truth[:, 3].to(device), ground_truth[:, 3:].to(device)\n",
    "        ex_input = ex_input.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        va_output, ex_output, au_output = ground_truth[:, :2].to(device), \\\n",
    "            prediction[:, 2:10].to(device), prediction[:, 10:].to(device)\n",
    "        \n",
    "        \n",
    "        va_loss = self.va_criterion(va_output, va_input)\n",
    "        ex_loss = self.ex_criterion(ex_output, ex_input)\n",
    "        au_loss = self.au_criterion(au_output, au_input)    \n",
    "        \n",
    "        total_loss = va_loss + ex_loss + au_loss\n",
    "        total_loss.requires_grad_ = True\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78ec7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, train_dataloader, task, val_dataloader,\n",
    "                        current_weights_name, best_competition_part):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    number_of_objects = len(train_dataloader)\n",
    "    to_train = True\n",
    "    \n",
    "    for i, (extracted_features, ground_truth) in enumerate(tqdm(train_dataloader, 0)):\n",
    "        extracted_features, ground_truth = extracted_features.to(device), ground_truth.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if task == 'VA':\n",
    "            valence_output, arousal_output = model(extracted_features)\n",
    "            prediction = torch.concat((valence_output, arousal_output), dim=1)\n",
    "            prediction_ = prediction\n",
    "        elif task == 'EX':\n",
    "            ground_truth = ground_truth.unsqueeze(1).long()\n",
    "            prediction = model(extracted_features).unsqueeze(2)\n",
    "            _, prediction_ = torch.max(prediction.data, 1)\n",
    "        elif task == 'AU':\n",
    "            prediction = model(extracted_features)\n",
    "            prediction_ = ((prediction >= 0.5) * 1)\n",
    "        \n",
    "        iteration_loss = criterion(prediction, ground_truth)\n",
    "        iteration_loss.backward()\n",
    "        running_loss += iteration_loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i == 0:\n",
    "            epoch_prediction = prediction_\n",
    "            epoch_ground_truth = ground_truth\n",
    "        else:\n",
    "            epoch_prediction = torch.concat((epoch_prediction, prediction_), dim=0)\n",
    "            epoch_ground_truth = torch.concat((epoch_ground_truth, ground_truth), dim=0)\n",
    "        \n",
    "        _, iteration_competition_part = eval_one_epoch(model=model, criterion=criterion, \n",
    "            val_dataloader=val_dataloader, task=task, to_print=False)\n",
    "        \n",
    "        if iteration_competition_part > best_competition_part:\n",
    "            if current_weights_name == '':\n",
    "                pass\n",
    "            else:\n",
    "                os.remove(current_weights_name)\n",
    "            best_competition_part = iteration_competition_part\n",
    "            torch.save(model.state_dict(), weights_dir+f'{task}_{best_competition_part:3f}.pt')\n",
    "            current_weights_name = weights_dir+f'{task}_{best_competition_part:3f}.pt'\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'best {task} competition part = {best_competition_part:3f}, \\\n",
    "current {task} competition part = {iteration_competition_part:3f}')\n",
    "            \n",
    "    epoch_loss = running_loss / number_of_objects\n",
    "    competition_part = evaluate_model(epoch_prediction, epoch_ground_truth, task=task)\n",
    "    \n",
    "    print(f'train evaluations:')\n",
    "    print(f'task {task}: loss = {epoch_loss:3f}, {task} part = {competition_part:3f}')\n",
    "    \n",
    "    return current_weights_name, best_competition_part, to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "650a08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(model, criterion, val_dataloader, task, to_print=True):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    number_of_objects = len(val_dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (extracted_features, ground_truth) in enumerate(val_dataloader, 0):\n",
    "            extracted_features, ground_truth = extracted_features.to(device), ground_truth.to(device)\n",
    "\n",
    "            if task == 'VA':\n",
    "                valence_output, arousal_output = model(extracted_features)\n",
    "                prediction = torch.concat((valence_output, arousal_output), dim=1)\n",
    "                prediction_ = prediction\n",
    "            elif task == 'EX':\n",
    "                ground_truth = ground_truth.unsqueeze(1).long()\n",
    "                prediction = model(extracted_features).unsqueeze(2)\n",
    "                _, prediction_ = torch.max(prediction.data, 1)\n",
    "            elif task == 'AU':\n",
    "                prediction = model(extracted_features)\n",
    "                prediction_ = ((prediction >= 0.5) * 1)\n",
    "\n",
    "            iteration_loss = criterion(prediction, ground_truth)\n",
    "            running_loss += iteration_loss.item()\n",
    "\n",
    "            if i == 0:\n",
    "                epoch_prediction = prediction_\n",
    "                epoch_ground_truth = ground_truth\n",
    "            else:\n",
    "                epoch_prediction = torch.concat((epoch_prediction, prediction_), dim=0)\n",
    "                epoch_ground_truth = torch.concat((epoch_ground_truth, ground_truth), dim=0)\n",
    "            \n",
    "    epoch_loss = running_loss / number_of_objects\n",
    "    competition_part = evaluate_model(epoch_prediction, epoch_ground_truth, task=task)\n",
    "    \n",
    "    if to_print:\n",
    "        print(f'validation evaluations:')\n",
    "        print(f'task {task}: loss = {epoch_loss:3f}, {task} part = {competition_part:3f}')\n",
    "    \n",
    "    return epoch_loss, competition_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d018aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emo_weights(y_train):\n",
    "    unique, counts = torch.unique(y_train, return_counts=True)\n",
    "    n_classes = len(unique)\n",
    "    class_weight = 1 / counts\n",
    "    class_weight /= class_weight.min()\n",
    "    class_weight = class_weight.to(device)\n",
    "    class_weight = class_weight.to(torch.float)\n",
    "\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f560fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_unit_weights(targets):\n",
    "    action_unit_positive_weights = [1 / torch.sum(targets[:, i] == 1).item() * (targets.shape[0] / 2) for i in range(targets.shape[1])]\n",
    "    action_unit_negative_weights = [1 / torch.sum(targets[:, i] == 0).item() * (targets.shape[0] / 2) for i in range(targets.shape[1])]\n",
    "\n",
    "    action_unit_positive_weights = torch.tensor(data=action_unit_positive_weights,\n",
    "        dtype=torch.float, device=device).unsqueeze(1)\n",
    "    action_unit_negative_weights = torch.tensor(data=action_unit_negative_weights,\n",
    "        dtype=torch.float, device=device).unsqueeze(1)\n",
    "    action_units_weights = torch.concat((action_unit_negative_weights, action_unit_positive_weights), dim=1)\n",
    "    return action_unit_positive_weights.squeeze(0), action_unit_negative_weights.squeeze(0), action_units_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f866ec",
   "metadata": {},
   "source": [
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4651a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99854905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model (./models/efficientnet_affectnet.pt) was correctly load\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_weights = {}\n",
    "load = torch.load(model_path)\n",
    "\n",
    "weights = load.classifier.weight.cpu().data.numpy()\n",
    "bias = load.classifier.bias.cpu().data.numpy()\n",
    "model_weights['efficientnet_based'] = {'weights': weights, 'bias': bias}\n",
    "print(f'model ({model_path}) was correctly load\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b123db",
   "metadata": {},
   "source": [
    "$ features = Xw^{T} + b$ \\\n",
    "*Logit Function*:\n",
    "$ L = ln\\frac{p}{1 - p}$*, where* $p = \\frac{1}{1 + e^{-L}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "573b8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(features, classifier_weights, classifier_bias, logits=True):\n",
    "    xs = np.dot(features, np.transpose(classifier_weights)) + classifier_bias\n",
    "\n",
    "    if logits:\n",
    "        return xs\n",
    "    else:\n",
    "        e_x = np.exp(xs - np.max(xs, axis=1)[:,np.newaxis])\n",
    "        return e_x / e_x.sum(axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2b35da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_features(model_path):\n",
    "    global_features = []\n",
    "    images = []\n",
    "    images_names = []\n",
    "    feature_extractor_model = torch.load(model_path)\n",
    "    if isinstance(feature_extractor_model, dict):\n",
    "        if 'inception_resnet' in correct_path:\n",
    "            feature_extractor_model = facenet_pytorch.InceptionResnetV1(pretrained='vggface2')\n",
    "            feature_extractor_model.logits = torch.nn.Identity()\n",
    "            feature_extractor_model.last_bn = torch.nn.Identity()\n",
    "            feature_extractor_model.last_linear = torch.nn.Identity()\n",
    "\n",
    "        else:\n",
    "            print(\"!densenet doesn't match keys\")\n",
    "            return global_features, images_names\n",
    "    else:\n",
    "        feature_extractor_model.classifier = torch.nn.Identity()\n",
    "    feature_extractor_model.to(device)\n",
    "    feature_extractor_model.eval()\n",
    "    for dir in tqdm(os.listdir(data_root)):\n",
    "        frames_dir = os.path.join(data_root, dir)\n",
    "        for image_name in os.listdir(frames_dir):\n",
    "            image_name = os.path.join(frames_dir, image_name)\n",
    "            if image_name.lower().endswith('.jpg'):\n",
    "                image = Image.open(image_name)\n",
    "                image_tensor = transforms(image)\n",
    "                if image.size:\n",
    "                    images_names.append(image_name)\n",
    "                    images.append(image_tensor)\n",
    "                    if len(images) >= 64:\n",
    "                        with torch.no_grad():\n",
    "                            features = feature_extractor_model(torch.stack(images, dim=0).to(device))\n",
    "                        features = features.data.cpu().numpy()\n",
    "\n",
    "                        if len(global_features):\n",
    "                            global_features = np.concatenate((global_features, features), axis=0)\n",
    "                        else:\n",
    "                            global_features = features\n",
    "                        \n",
    "                        # reset images\n",
    "                        images.clear()\n",
    "                        \n",
    "    if len(images): # get all the remains\n",
    "        features = feature_extractor_model(torch.stack(images, dim=0).to(device))\n",
    "        features = features.data.cpu().numpy() \n",
    "\n",
    "    if len(global_features):\n",
    "        global_features = np.concatenate((global_features, features), axis=0)\n",
    "    else:\n",
    "        global_features = features \n",
    "\n",
    "    images.clear()\n",
    "    return global_features, images_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3223c690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb7ca3e74fe462d9d992c23149a7622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_features, images_names = get_global_features(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8087630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!saving ./models/efficientnet_affectnet.pt features, scores and images_names, with logits=True\n"
     ]
    }
   ],
   "source": [
    "scores = get_prob(global_features, weights, bias, logits=logits)\n",
    "filename2featuresAll = {}\n",
    "print(f'!saving {model_path} features, scores and images_names, with logits={logits}')\n",
    "filename2featuresAll = {img_name:(global_feature,score) for img_name,global_feature,score in zip(images_names,global_features,scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c1df052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_target(annotation_file, filename2featuresAll):\n",
    "    with open(annotation_file) as f:\n",
    "        mtl_lines = f.read().splitlines()\n",
    "    n_missed=0\n",
    "    features, y_VA, y_EX, y_AU, y_AR = [], [], [], [], []\n",
    "    mask_VA, mask_EX, mask_AU, mask_AR = [], [], [], []\n",
    "    for line in mtl_lines[1:]:\n",
    "        target_values = line.split(',')\n",
    "        image_name = os.path.join(data_root, target_values[0].replace('/', '\\\\'))\n",
    "        image_name.replace('\\\\', '\\\\\\\\')\n",
    "        valence_value = float(target_values[1])\n",
    "        arousal_value = float(target_values[2])\n",
    "        expression_value = int(target_values[3])\n",
    "        au_values = [int(au_value) for au_value in target_values[4:]]\n",
    "        \n",
    "        VA_threshold = -5\n",
    "        EX_threshold = -1\n",
    "\n",
    "        mask_va = (valence_value > VA_threshold and arousal_value > VA_threshold)\n",
    "        if not mask_va:\n",
    "            valence_value = arousal_value = 0\n",
    "\n",
    "        # mask_ar = (arousal_value > VA_threshold)\n",
    "        # if not mask_ar:\n",
    "        #     arousal_value = 0\n",
    "        \n",
    "        mask_ex = (expression_value > EX_threshold)\n",
    "        if not mask_ex:\n",
    "            expression_value = 0\n",
    "            \n",
    "        mask_au = min(au_values) >= 0\n",
    "        if not mask_au:\n",
    "            au_values = [0]*len(au_values)\n",
    "\n",
    "        if mask_va or mask_ex or mask_au:\n",
    "            if image_name in filename2featuresAll:\n",
    "                features.append(np.concatenate((filename2featuresAll[image_name][0], \n",
    "                                                    filename2featuresAll[image_name][1])))\n",
    "                y_VA.append((valence_value, arousal_value))\n",
    "                mask_VA.append(mask_va)\n",
    "\n",
    "                # y_AR.append(arousal_value)\n",
    "                # mask_AR.append(mask_ar)\n",
    "                \n",
    "                y_EX.append(expression_value)\n",
    "                mask_EX.append(mask_ex)\n",
    "                \n",
    "                y_AU.append(au_values)\n",
    "                mask_AU.append(mask_au)\n",
    "            else:\n",
    "                n_missed += 1\n",
    "\n",
    "    features = np.array(features)\n",
    "    y_VA = np.array(y_VA)\n",
    "    # y_AR = np.array(y_AR)\n",
    "    y_EX = np.array(y_EX)\n",
    "    y_AU = np.array(y_AU)\n",
    "\n",
    "    mask_VA = np.array(mask_VA).astype(np.float32)\n",
    "    # mask_AR = np.array(mask_AR).astype(np.float32)\n",
    "    mask_EX = np.array(mask_EX).astype(np.float32)\n",
    "    mask_AU = np.array(mask_AU).astype(np.float32)\n",
    "\n",
    "    print(f'shapes:\\n\\\n",
    "            features = {features.shape}\\n\\\n",
    "            valence = {y_VA.shape}\\n\\\n",
    "            expression = {y_EX.shape}\\n\\\n",
    "            aus = {y_AU.shape}\\n')\n",
    "    \n",
    "    assert features.shape[0] == y_VA.shape[0] == y_EX.shape[0] == y_AU.shape[0]\n",
    "    print(f'assert passed...\\nnum_missed: {n_missed}')\n",
    "    \n",
    "    # return features, y_VA, y_EX, y_AU, mask_VA, mask_EX, mask_AU, y_AR, mask_AR\n",
    "    return features, y_VA, y_EX, y_AU, mask_VA, mask_EX, mask_AU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a06f3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes:\n",
      "            features = (142333, 1290)\n",
      "            valence = (142333, 2)\n",
      "            expression = (142333,)\n",
      "            aus = (142333, 12)\n",
      "\n",
      "assert passed...\n",
      "num_missed: 0\n",
      "shapes:\n",
      "            features = (26876, 1290)\n",
      "            valence = (26876, 2)\n",
      "            expression = (26876,)\n",
      "            aus = (26876, 12)\n",
      "\n",
      "assert passed...\n",
      "num_missed: 0\n"
     ]
    }
   ],
   "source": [
    "seed_everything(1996)\n",
    "\n",
    "train_features, train_y_VA, train_y_EX, train_y_AU, \\\n",
    "train_mask_VA,train_mask_EX, train_mask_AU = get_features_and_target(annotation_file=train_annotation_file, \n",
    "                                                                     filename2featuresAll=filename2featuresAll)\n",
    "\n",
    "val_features, val_y_VA, val_y_EX, val_y_AU, \\\n",
    "val_mask_VA, val_mask_EX, val_mask_AU = get_features_and_target(annotation_file=val_annotation_file, \n",
    "                                                                filename2featuresAll=filename2featuresAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e1d2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1996)\n",
    "\n",
    "X_VA_train, y_VA_train = torch.tensor(train_features[train_mask_VA == 1], dtype=torch.float32), torch.tensor(train_y_VA[train_mask_VA == 1], dtype=torch.float32)\n",
    "X_VA_val, y_VA_val = torch.tensor(val_features[val_mask_VA == 1], dtype=torch.float32), torch.tensor(val_y_VA[val_mask_VA == 1], dtype=torch.float32)\n",
    "\n",
    "VA_train_dataset = TensorDataset(X_VA_train, y_VA_train)\n",
    "VA_val_dataset = TensorDataset(X_VA_val, y_VA_val)\n",
    "\n",
    "VA_trainloader = DataLoader(VA_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "VA_valloader = DataLoader(VA_val_dataset, batch_size=len(X_VA_val), shuffle=False)\n",
    "\n",
    "X_EX_train, y_EX_train = torch.tensor(train_features[train_mask_EX == 1], dtype=torch.float32), torch.tensor(train_y_EX[train_mask_EX == 1], dtype=torch.float32)\n",
    "X_EX_val, y_EX_val = torch.tensor(val_features[val_mask_EX == 1], dtype=torch.float32), torch.tensor(val_y_EX[val_mask_EX == 1], dtype=torch.float32)\n",
    "\n",
    "EX_train_dataset = TensorDataset(X_EX_train, y_EX_train)\n",
    "EX_val_dataset = TensorDataset(X_EX_val, y_EX_val)\n",
    "\n",
    "EX_trainloader = DataLoader(EX_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "EX_valloader = DataLoader(EX_val_dataset, batch_size=len(X_EX_val), shuffle=False)\n",
    "\n",
    "X_AU_train, y_AU_train = torch.tensor(train_features[train_mask_AU == 1], dtype=torch.float32), torch.tensor(train_y_AU[train_mask_AU == 1], dtype=torch.float32)\n",
    "X_AU_val, y_AU_val = torch.tensor(val_features[val_mask_AU == 1], dtype=torch.float32), torch.tensor(val_y_AU[val_mask_AU == 1], dtype=torch.float32)\n",
    "\n",
    "AU_train_dataset = TensorDataset(X_AU_train, y_AU_train)\n",
    "AU_val_dataset = TensorDataset(X_AU_val, y_AU_val)\n",
    "\n",
    "AU_trainloader = DataLoader(AU_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "AU_valloader = DataLoader(AU_val_dataset, batch_size=len(X_AU_val), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c95815cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of legit observations:\n",
      "train examples:\n",
      "valence-arousal features: 103917, valence-arousal targets: 103917\n",
      "expression features: 90645, expression targets: 90645\n",
      "action unit features: 103316, action unit targets: 103316\n",
      "\n",
      "validation examples:\n",
      "valence-arousal features: 26876, valence-arousal targets: 26876\n",
      "expression features: 15440, expression targets: 15440\n",
      "action unit features: 26876, action unit targets: 26876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'number of legit observations:\\n\\\n",
    "train examples:\\n\\\n",
    "valence-arousal features: {len(X_VA_train)}, valence-arousal targets: {len(y_VA_train)}\\n\\\n",
    "expression features: {len(X_EX_train)}, expression targets: {len(y_EX_train)}\\n\\\n",
    "action unit features: {len(X_AU_train)}, action unit targets: {len(y_AU_train)}\\n\\n\\\n",
    "validation examples:\\n\\\n",
    "valence-arousal features: {len(X_VA_val)}, valence-arousal targets: {len(y_VA_val)}\\n\\\n",
    "expression features: {len(X_EX_val)}, expression targets: {len(y_EX_val)}\\n\\\n",
    "action unit features: {len(X_AU_val)}, action unit targets: {len(y_AU_val)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb66b8",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c3ac3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class valence_arousal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.55)\n",
    "        \n",
    "        self.valence_head = nn.Linear(in_features=self.in_features, out_features=1)\n",
    "        self.arousal_head = nn.Linear(in_features=self.in_features, out_features=1)\n",
    "        \n",
    "        self.head_activation = nn.Tanh()\n",
    "    \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        valence_output = self.head_activation(self.valence_head(output))\n",
    "        arousal_output = self.head_activation(self.arousal_head(output))\n",
    "        \n",
    "        return valence_output, arousal_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e311e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class expression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.expression_head = nn.Linear(in_features=self.in_features, out_features=8)\n",
    "        \n",
    "        self.head_activation = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        expression_output = self.head_activation(self.expression_head(output))\n",
    "        \n",
    "        return expression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fee3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class action_unit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.6)\n",
    "        \n",
    "        self.action_unit_head = nn.Linear(in_features=self.in_features, out_features=12)\n",
    "        \n",
    "        self.head_activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        action_unit_output = self.head_activation(self.action_unit_head(output))\n",
    "        \n",
    "        return action_unit_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "33891f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXAU(nn.Module):\n",
    "    def __init__(self, pretrained_ex=False):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.expression_model = expression()\n",
    "        self.pretrained_ex = pretrained_ex\n",
    "        if pretrained_ex:\n",
    "            best_ex_weights = './new_weights/cropped-aligned/batch=1024, logits=True/EX_0.370579.pt'\n",
    "            self.expression_model.load_state_dict(torch.load(best_ex_weights))\n",
    "            self.expression_model.expression_head = nn.Identity()\n",
    "            self.expression_model.eval()\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.35)\n",
    "        \n",
    "        self.action_unit_head = nn.Linear(in_features=self.in_features*2, out_features=12)\n",
    "        self.head_activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        if self.pretrained_ex:\n",
    "            ex_output = self.expression_model(extracted_features)\n",
    "            output = torch.concat((output, ex_output), dim=1)\n",
    "            \n",
    "        action_unit_output = self.head_activation(self.action_unit_head(output))\n",
    "        \n",
    "        return action_unit_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d46148ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEX(nn.Module):\n",
    "    def __init__(self, pretrained_va=False):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.valence_arousal_model = valence_arousal()\n",
    "        self.pretrained_va = pretrained_va\n",
    "        if pretrained_va:\n",
    "            best_va_weights = './new_weights/cropped-aligned/batch=1024, logits=True/VA_0.469680.pt'\n",
    "            self.valence_arousal_model.load_state_dict(torch.load(best_va_weights))\n",
    "            self.valence_arousal_model.valence_head = nn.Identity()\n",
    "            self.valence_arousal_model.arousal_head = nn.Identity()\n",
    "            self.valence_arousal_model.head_activation = nn.Identity()\n",
    "            self.valence_arousal_model.eval()\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.expression_head = nn.Linear(in_features=self.in_features*3, out_features=8)\n",
    "        self.head_activation = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        if self.pretrained_va:\n",
    "            valence_output, arousal_output = self.valence_arousal_model(extracted_features)\n",
    "            va_output = torch.concat((valence_output, arousal_output), dim=1)\n",
    "            output = torch.concat((output, va_output), dim=1)\n",
    "        \n",
    "        expression_output = self.head_activation(self.expression_head(output))\n",
    "        \n",
    "        return expression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ceae04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXVA(nn.Module):\n",
    "    def __init__(self, pretrained_ex=False):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.expression_model = expression()\n",
    "        self.pretrained_ex = pretrained_ex\n",
    "        if pretrained_ex:\n",
    "            best_ex_weights = './new_weights/cropped-aligned/batch=1024, logits=True/EX_0.370579.pt'\n",
    "            self.expression_model.load_state_dict(torch.load(best_ex_weights))\n",
    "            self.expression_model.expression_head = nn.Identity()\n",
    "            self.expression_model.eval()\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.65)\n",
    "        \n",
    "        self.valence_head = nn.Linear(in_features=self.in_features*2, out_features=1)\n",
    "        self.arousal_head = nn.Linear(in_features=self.in_features*2, out_features=1)\n",
    "        self.head_activation = nn.Tanh()\n",
    "        \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        if self.pretrained_ex:\n",
    "            ex_output = self.expression_model(extracted_features)\n",
    "            output = torch.concat((output, ex_output), dim=1)\n",
    "            \n",
    "        valence_output = self.head_activation(self.valence_head(output))\n",
    "        arousal_output = self.head_activation(self.arousal_head(output))\n",
    "        \n",
    "        return valence_output, arousal_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "807541c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_model = valence_arousal().to(device)\n",
    "va_optimizer = torch.optim.Adam(va_model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "ex_model = expression().to(device)\n",
    "ex_optimizer = torch.optim.Adam(ex_model.parameters(), lr=1e-3)\n",
    "\n",
    "au_model = action_unit().to(device)\n",
    "au_optimizer = torch.optim.Adam(au_model.parameters(), lr=1e-3)\n",
    "\n",
    "exau_model = EXAU(pretrained_ex=True).to(device)\n",
    "exau_optimizer = torch.optim.Adam(exau_model.parameters(), lr=1e-3)\n",
    "\n",
    "vaex_model = VAEX(pretrained_va=True).to(device)\n",
    "vaex_optimizer = torch.optim.Adam(vaex_model.parameters(), lr=1e-3)\n",
    "\n",
    "exva_model = EXVA(pretrained_ex=True).to(device)\n",
    "exva_optimizer = torch.optim.Adam(exva_model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728a803",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1df40dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 2\n",
    "\n",
    "va_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(va_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "va_criterion = ABAWCCCLoss()\n",
    "\n",
    "ex_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(ex_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "emotion_weights = get_emo_weights(y_EX_train)\n",
    "ex_criterion = nn.CrossEntropyLoss(weight=emotion_weights)\n",
    "\n",
    "au_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(au_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "action_unit_positive_weights, _, _ = get_action_unit_weights(y_AU_train)\n",
    "action_unit_positive_weights = action_unit_positive_weights.reshape(-1, 12)\n",
    "au_criterion = nn.BCEWithLogitsLoss(pos_weight=action_unit_positive_weights)\n",
    "\n",
    "exau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(exau_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "exau_criterion = nn.BCEWithLogitsLoss(pos_weight=action_unit_positive_weights)\n",
    "\n",
    "vaex_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(vaex_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "vaex_criterion = nn.CrossEntropyLoss(weight=emotion_weights)\n",
    "\n",
    "exva_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(exva_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "exva_criterion = ABAWCCCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618cc482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_va_weights_name = ''\n",
    "current_ex_weights_name = ''\n",
    "current_au_weights_name = ''\n",
    "current_exau_weights_name = ''\n",
    "current_vaex_weights_name = ''\n",
    "current_exva_weights_name = ''\n",
    "\n",
    "best_competition_part_va = 0\n",
    "best_competition_part_ex = 0\n",
    "best_competition_part_au = 0\n",
    "best_competition_part_exau = 0\n",
    "best_competition_part_vaex = 0\n",
    "best_competition_part_exva = 0\n",
    "\n",
    "train_va = False\n",
    "train_ex = False\n",
    "train_au = False\n",
    "train_exau = False\n",
    "train_vaex = False\n",
    "train_exva = True\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    if epoch in range(9):\n",
    "        print(f'epoch №0{epoch+1} is currently running...')\n",
    "    else:\n",
    "        print(f'epoch №{epoch+1} is currently running...')\n",
    "    \n",
    "    # VALENCE-AROUSAL\n",
    "    if train_va:\n",
    "        current_va_weights_name, best_competition_part_va, train_va = train_one_epoch(model=va_model, \n",
    "            criterion=va_criterion, optimizer=va_optimizer, train_dataloader=VA_trainloader, \n",
    "            val_dataloader=VA_valloader, task='VA', current_weights_name=current_va_weights_name, \n",
    "            best_competition_part=best_competition_part_va)\n",
    "        va_eval_loss, _ = eval_one_epoch(model=va_model, criterion=va_criterion, val_dataloader=VA_valloader, task='VA')\n",
    "\n",
    "        previous_va_lr = va_optimizer.param_groups[0]['lr']\n",
    "        va_scheduler.step(va_eval_loss)\n",
    "    \n",
    "    # EXPRESSION\n",
    "    if train_ex:\n",
    "        current_ex_weights_name, best_competition_part_ex, train_ex = train_one_epoch(model=ex_model, \n",
    "            criterion=ex_criterion, optimizer=ex_optimizer, train_dataloader=EX_trainloader, \n",
    "            val_dataloader=EX_valloader, task='EX', current_weights_name=current_ex_weights_name, \n",
    "            best_competition_part=best_competition_part_ex)\n",
    "        ex_eval_loss, _ = eval_one_epoch(model=ex_model, criterion=ex_criterion, val_dataloader=EX_valloader, task='EX')\n",
    "\n",
    "        previous_ex_lr = ex_optimizer.param_groups[0]['lr']\n",
    "        ex_scheduler.step(ex_eval_loss)\n",
    "    \n",
    "    # ACTION UNIT\n",
    "    if train_au:\n",
    "        current_au_weights_name, best_competition_part_au, train_au = train_one_epoch(model=au_model, \n",
    "            criterion=au_criterion, optimizer=au_optimizer, train_dataloader=AU_trainloader, \n",
    "            val_dataloader=AU_valloader, task='AU', current_weights_name=current_au_weights_name, \n",
    "            best_competition_part=best_competition_part_au)\n",
    "        au_eval_loss, _ = eval_one_epoch(model=au_model, criterion=au_criterion, val_dataloader=AU_valloader, task='AU')\n",
    "\n",
    "        previous_au_lr = au_optimizer.param_groups[0]['lr']\n",
    "        au_scheduler.step(au_eval_loss)\n",
    "    \n",
    "    if train_exau:\n",
    "        current_exau_weights_name, best_competition_part_exau, _ = train_one_epoch(model=exau_model, \n",
    "                criterion=exau_criterion, optimizer=exau_optimizer, train_dataloader=AU_trainloader, \n",
    "                val_dataloader=AU_valloader, task='AU', current_weights_name=current_exau_weights_name, \n",
    "                best_competition_part=best_competition_part_exau)\n",
    "        exau_eval_loss, _ = eval_one_epoch(model=exau_model, criterion=exau_criterion, val_dataloader=AU_valloader, task='AU')\n",
    "\n",
    "        previous_exau_lr = exau_optimizer.param_groups[0]['lr']\n",
    "        exau_scheduler.step(exau_eval_loss)\n",
    "        \n",
    "    if train_vaex:\n",
    "        current_vaex_weights_name, best_competition_part_vaex, train_vaex = train_one_epoch(model=vaex_model, \n",
    "            criterion=vaex_criterion, optimizer=vaex_optimizer, train_dataloader=EX_trainloader, \n",
    "            val_dataloader=EX_valloader, task='EX', current_weights_name=current_vaex_weights_name, \n",
    "            best_competition_part=best_competition_part_vaex)\n",
    "        vaex_eval_loss, _ = eval_one_epoch(model=vaex_model, criterion=vaex_criterion, val_dataloader=EX_valloader, task='EX')\n",
    "\n",
    "        previous_vaex_lr = vaex_optimizer.param_groups[0]['lr']\n",
    "        vaex_scheduler.step(vaex_eval_loss)\n",
    "        \n",
    "    if train_exva:\n",
    "        current_exva_weights_name, best_competition_part_exva, train_exva = train_one_epoch(model=exva_model, \n",
    "            criterion=exva_criterion, optimizer=exva_optimizer, train_dataloader=VA_trainloader, \n",
    "            val_dataloader=VA_valloader, task='VA', current_weights_name=current_exva_weights_name, \n",
    "            best_competition_part=best_competition_part_exva)\n",
    "        exva_eval_loss, _ = eval_one_epoch(model=exva_model, criterion=exva_criterion, val_dataloader=VA_valloader, task='VA')\n",
    "\n",
    "        previous_exva_lr = exva_optimizer.param_groups[0]['lr']\n",
    "        exva_scheduler.step(exva_eval_loss)\n",
    "    \n",
    "    # LEARNING RATE DECREASE\n",
    "#     print(f'task VA: previous lr: {previous_va_lr}, scheduled lr: {va_optimizer.param_groups[0][\"lr\"]}')\n",
    "#     print(f'task EX: previous lr: {previous_ex_lr}, scheduled lr: {ex_optimizer.param_groups[0][\"lr\"]}')\n",
    "#     print(f'task AU: previous lr: {previous_au_lr}, scheduled lr: {au_optimizer.param_groups[0][\"lr\"]}')\n",
    "#     print(f'task EXAU: previous lr: {previous_exau_lr}, scheduled lr: {exau_optimizer.param_groups[0][\"lr\"]}')\n",
    "#     print(f'task VAEX: previous lr: {previous_vaex_lr}, scheduled lr: {vaex_optimizer.param_groups[0][\"lr\"]}')      \n",
    "    print(f'task EXVA: previous lr: {previous_exva_lr}, scheduled lr: {exva_optimizer.param_groups[0][\"lr\"]}')          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb87ca4",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0731204",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensemble(nn.Module):\n",
    "    def __init__(self, model_va, model_ex, model_au):\n",
    "        super().__init__()\n",
    "        self.model_va = model_va\n",
    "        self.model_ex = model_ex\n",
    "        self.model_au = model_au\n",
    "        \n",
    "        self.model_va.eval()\n",
    "        self.model_ex.eval()\n",
    "        self.model_au.eval()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            va_output, ar_output = self.model_va(x)\n",
    "            ex_output = self.model_ex(x)\n",
    "            au_output = self.model_au(x)\n",
    "\n",
    "        return va_output, ar_output, ex_output, au_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce5a203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ensemble(ensemble, val_features, val_targets, val_targets_mask, print_f1_ex_statistic=False,\n",
    "                  print_f1_au_statistic=False):\n",
    "    with torch.no_grad():\n",
    "        va_output, ar_output, ex_output, au_output = ensemble(val_features)\n",
    "\n",
    "        va_input = val_targets[0][val_targets_mask[0] == 1]\n",
    "        va_output = torch.concat((va_output, ar_output), dim=1)\n",
    "        \n",
    "        va_competition_part = evaluate_model(va_output, va_input, task='VA')\n",
    "        \n",
    "        ex_input = val_targets[1][val_targets_mask[1] == 1].unsqueeze(1).long()\n",
    "        ex_output = ex_output.unsqueeze(2)\n",
    "        _, ex_output = torch.max(ex_output.data, 1)\n",
    "        ex_output = ex_output[val_targets_mask[1] == 1]\n",
    "        \n",
    "        ex_competition_part = evaluate_model(ex_output, ex_input, task='EX')\n",
    "\n",
    "        au_input = val_targets[2][val_targets_mask[2] == 1]\n",
    "        au_output = ((au_output >= 0.5) * 1)\n",
    "        au_output = au_output[val_targets_mask[2] == 1]\n",
    "        \n",
    "        au_competition_part = evaluate_model(au_output, au_input, task='AU')\n",
    "\n",
    "        abaw_metric = va_competition_part + ex_competition_part + au_competition_part\n",
    "    if print_f1_ex_statistic:\n",
    "        print(sklearn.metrics.classification_report(ex_input.data.cpu().numpy(), ex_output.data.cpu().numpy()))\n",
    "    if print_f1_au_statistic:\n",
    "        print(sklearn.metrics.classification_report(au_input.data.cpu().numpy(), au_output.data.cpu().numpy()))\n",
    "    print(f'ABAW result: {abaw_metric:3f}, valence-arousal: {va_competition_part:3f}, \\\n",
    "expression: {ex_competition_part:3f}, action unit: {au_competition_part:3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13c9b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1996)\n",
    "\n",
    "val_features_ = torch.tensor(data=val_features, dtype=torch.float, device=device)\n",
    "val_targets = [torch.tensor(data=data, dtype=torch.float, device=device) for data in [val_y_VA, val_y_EX, val_y_AU]]\n",
    "val_targets_mask = [val_mask_VA, val_mask_EX, val_mask_AU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42203d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'current valence-arousal weights path: \"{current_va_weights_name}\",\\n\\\n",
    "current expression weights path: \"{current_ex_weights_name}\",\\n\\\n",
    "current action_unit weights path: \"{current_au_weights_name}\",\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "543ca2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_arousal_model = valence_arousal().to(device).eval()\n",
    "valence_arousal_model.load_state_dict(torch.load(current_va_weights_name))\n",
    "\n",
    "expression_model = expression().to(device).eval()\n",
    "expression_model.load_state_dict(torch.load(current_ex_weights_name))\n",
    "\n",
    "action_unit_model = action_unit().to(device).eval()\n",
    "action_unit_model.load_state_dict(torch.load(current_au_weights_name))\n",
    "\n",
    "ensemble = ensemble(model_va=valence_arousal_model, model_ex=expression_model, model_au=action_unit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "c20c2a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABAW result: 1.330468, valence-arousal: 0.452668, expression: 0.370579, action unit: 0.507221\n"
     ]
    }
   ],
   "source": [
    "eval_ensemble(ensemble, val_features_, val_targets, val_targets_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b287008",
   "metadata": {},
   "source": [
    "# best weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7670bcca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best VA weights: ./new_weights/cropped-aligned/batch=1024, logits=True/VA_0.469680.pt,\n",
      "best EX weights: ./new_weights/cropped-aligned/batch=1024, logits=True/EX_0.370579.pt\n",
      "best AU weights: ./new_weights/cropped-aligned/batch=1024, logits=True/AU_0.507221.pt\n",
      "best EXAU weights: ./new_weights/cropped-aligned/batch=1024, logits=True/exau_0.510846.pt\n",
      "best VAEX weights: ./new_weights/cropped-aligned/batch=1024, logits=True/vaex_0.383444.pt\n"
     ]
    }
   ],
   "source": [
    "all_va_weights = [weights_dir+weights for weights in os.listdir(weights_dir) if 'VA' in weights]\n",
    "all_ex_weights = [weights_dir+weights for weights in os.listdir(weights_dir) if 'EX' in weights]\n",
    "all_au_weights = [weights_dir+weights for weights in os.listdir(weights_dir) if 'AU' in weights]\n",
    "all_exau_weights = [weights_dir+weights for weights in os.listdir(weights_dir) if 'exau' in weights]\n",
    "\n",
    "max_va_part = 0\n",
    "max_ex_part = 0\n",
    "max_au_part = 0\n",
    "max_exau_part = 0\n",
    "\n",
    "best_va_weight = ''\n",
    "best_ex_weight = ''\n",
    "best_au_weight = ''\n",
    "best_exau_weight = weights_dir+'exau_0.510846.pt'\n",
    "best_vaex_weight = weights_dir+'vaex_0.383444.pt'\n",
    "\n",
    "for va_weight, ex_weight, au_weight in zip(all_va_weights, all_ex_weights, all_au_weights):\n",
    "    va_part = float(va_weight.split('_')[-1].split('.pt')[0])\n",
    "    ex_part = float(ex_weight.split('_')[-1].split('.pt')[0])\n",
    "    au_part = float(au_weight.split('_')[-1].split('.pt')[0])\n",
    "    \n",
    "    if va_part > max_va_part:\n",
    "        max_va_part = va_part\n",
    "        best_va_weight = va_weight\n",
    "    if ex_part > max_ex_part:\n",
    "        max_ex_part = ex_part\n",
    "        best_ex_weight = ex_weight\n",
    "    if au_part > max_au_part:\n",
    "        max_au_part = au_part\n",
    "        best_au_weight = au_weight\n",
    "\n",
    "print(f'best VA weights: {best_va_weight},\\n\\\n",
    "best EX weights: {best_ex_weight}\\n\\\n",
    "best AU weights: {best_au_weight}\\n\\\n",
    "best EXAU weights: {best_exau_weight}\\n\\\n",
    "best VAEX weights: {best_vaex_weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7d2858ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_arousal_model = valence_arousal().to(device)\n",
    "valence_arousal_model.load_state_dict(torch.load(best_va_weight))\n",
    "\n",
    "expression_model = expression().to(device)\n",
    "expression_model.load_state_dict(torch.load(best_ex_weight))\n",
    "\n",
    "action_unit_model = action_unit().to(device)\n",
    "action_unit_model.load_state_dict(torch.load(best_au_weight))\n",
    "\n",
    "best_ensemble = ensemble(model_va=valence_arousal_model, model_ex=expression_model, model_au=action_unit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c9ded811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.44      0.34      1886\n",
      "           1       0.16      0.47      0.23       487\n",
      "           2       0.35      0.60      0.44       565\n",
      "           3       0.31      0.38      0.34      1254\n",
      "           4       0.56      0.49      0.52      3751\n",
      "           5       0.70      0.41      0.52      1893\n",
      "           6       0.15      0.26      0.19      1003\n",
      "           7       0.56      0.28      0.38      4601\n",
      "\n",
      "    accuracy                           0.39     15440\n",
      "   macro avg       0.38      0.42      0.37     15440\n",
      "weighted avg       0.48      0.39      0.41     15440\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58      5531\n",
      "           1       0.42      0.46      0.44      2554\n",
      "           2       0.59      0.53      0.56      5442\n",
      "           3       0.68      0.47      0.56      8818\n",
      "           4       0.77      0.63      0.69     13224\n",
      "           5       0.76      0.62      0.68     11421\n",
      "           6       0.76      0.60      0.67      8319\n",
      "           7       0.22      0.36      0.28       782\n",
      "           8       0.17      0.27      0.21       757\n",
      "           9       0.17      0.35      0.22       808\n",
      "          10       0.90      0.79      0.84     20427\n",
      "          11       0.32      0.38      0.35      2934\n",
      "\n",
      "   micro avg       0.70      0.61      0.65     81017\n",
      "   macro avg       0.53      0.50      0.51     81017\n",
      "weighted avg       0.72      0.61      0.66     81017\n",
      " samples avg       0.55      0.52      0.50     81017\n",
      "\n",
      "ABAW result: 1.346921, valence-arousal: 0.469121, expression: 0.370579, action unit: 0.507221\n"
     ]
    }
   ],
   "source": [
    "eval_ensemble(best_ensemble, val_features_, val_targets, val_targets_mask, print_f1_au_statistic=True,\n",
    "    print_f1_ex_statistic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2d7239c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_action_unit_model = EXAU(pretrained_ex=True).to(device)\n",
    "expression_action_unit_model.load_state_dict(torch.load(best_exau_weight))\n",
    "\n",
    "exau_ensemble = ensemble(model_va=valence_arousal_model, model_ex=expression_model, model_au=expression_action_unit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9aded751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.44      0.34      1886\n",
      "           1       0.16      0.47      0.23       487\n",
      "           2       0.35      0.60      0.44       565\n",
      "           3       0.31      0.38      0.34      1254\n",
      "           4       0.56      0.49      0.52      3751\n",
      "           5       0.70      0.41      0.52      1893\n",
      "           6       0.15      0.26      0.19      1003\n",
      "           7       0.56      0.28      0.38      4601\n",
      "\n",
      "    accuracy                           0.39     15440\n",
      "   macro avg       0.38      0.42      0.37     15440\n",
      "weighted avg       0.48      0.39      0.41     15440\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.57      5531\n",
      "           1       0.42      0.48      0.45      2554\n",
      "           2       0.59      0.55      0.57      5442\n",
      "           3       0.68      0.50      0.58      8818\n",
      "           4       0.75      0.70      0.72     13224\n",
      "           5       0.75      0.64      0.69     11421\n",
      "           6       0.76      0.60      0.67      8319\n",
      "           7       0.20      0.36      0.26       782\n",
      "           8       0.12      0.34      0.18       757\n",
      "           9       0.17      0.35      0.23       808\n",
      "          10       0.89      0.80      0.84     20427\n",
      "          11       0.32      0.43      0.36      2934\n",
      "\n",
      "   micro avg       0.69      0.64      0.66     81017\n",
      "   macro avg       0.52      0.52      0.51     81017\n",
      "weighted avg       0.72      0.64      0.67     81017\n",
      " samples avg       0.54      0.54      0.50     81017\n",
      "\n",
      "ABAW result: 1.350546, valence-arousal: 0.469121, expression: 0.370579, action unit: 0.510846\n"
     ]
    }
   ],
   "source": [
    "eval_ensemble(exau_ensemble, val_features_, val_targets, val_targets_mask, print_f1_au_statistic=True,\n",
    "    print_f1_ex_statistic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "70f38971",
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_arousal_expression_model = VAEX(pretrained_va=True).to(device)\n",
    "valence_arousal_expression_model.load_state_dict(torch.load(best_vaex_weight))\n",
    "\n",
    "vaex_exau_ensemble = ensemble(model_va=valence_arousal_model, model_ex=valence_arousal_expression_model, \n",
    "    model_au=expression_action_unit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f964dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33      1886\n",
      "           1       0.17      0.37      0.23       487\n",
      "           2       0.34      0.61      0.44       565\n",
      "           3       0.32      0.37      0.34      1254\n",
      "           4       0.55      0.54      0.54      3751\n",
      "           5       0.68      0.48      0.56      1893\n",
      "           6       0.17      0.32      0.22      1003\n",
      "           7       0.50      0.34      0.40      4601\n",
      "\n",
      "    accuracy                           0.41     15440\n",
      "   macro avg       0.38      0.42      0.38     15440\n",
      "weighted avg       0.46      0.41      0.43     15440\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.57      5531\n",
      "           1       0.42      0.48      0.45      2554\n",
      "           2       0.59      0.55      0.57      5442\n",
      "           3       0.68      0.50      0.58      8818\n",
      "           4       0.75      0.70      0.72     13224\n",
      "           5       0.75      0.64      0.69     11421\n",
      "           6       0.76      0.60      0.67      8319\n",
      "           7       0.20      0.36      0.26       782\n",
      "           8       0.12      0.34      0.18       757\n",
      "           9       0.17      0.35      0.23       808\n",
      "          10       0.89      0.80      0.84     20427\n",
      "          11       0.32      0.43      0.36      2934\n",
      "\n",
      "   micro avg       0.69      0.64      0.66     81017\n",
      "   macro avg       0.52      0.52      0.51     81017\n",
      "weighted avg       0.72      0.64      0.67     81017\n",
      " samples avg       0.54      0.54      0.50     81017\n",
      "\n",
      "ABAW result: 1.363411, valence-arousal: 0.469121, expression: 0.383444, action unit: 0.510846\n"
     ]
    }
   ],
   "source": [
    "eval_ensemble(vaex_exau_ensemble, val_features_, val_targets, val_targets_mask, print_f1_au_statistic=True,\n",
    "    print_f1_ex_statistic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "affc4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaex_ensemble = ensemble(model_va=valence_arousal_model, model_ex=valence_arousal_expression_model, \n",
    "    model_au=action_unit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a37613cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33      1886\n",
      "           1       0.17      0.37      0.23       487\n",
      "           2       0.34      0.61      0.44       565\n",
      "           3       0.32      0.37      0.34      1254\n",
      "           4       0.55      0.54      0.54      3751\n",
      "           5       0.68      0.48      0.56      1893\n",
      "           6       0.17      0.32      0.22      1003\n",
      "           7       0.50      0.34      0.40      4601\n",
      "\n",
      "    accuracy                           0.41     15440\n",
      "   macro avg       0.38      0.42      0.38     15440\n",
      "weighted avg       0.46      0.41      0.43     15440\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58      5531\n",
      "           1       0.42      0.46      0.44      2554\n",
      "           2       0.59      0.53      0.56      5442\n",
      "           3       0.68      0.47      0.56      8818\n",
      "           4       0.77      0.63      0.69     13224\n",
      "           5       0.76      0.62      0.68     11421\n",
      "           6       0.76      0.60      0.67      8319\n",
      "           7       0.22      0.36      0.28       782\n",
      "           8       0.17      0.27      0.21       757\n",
      "           9       0.17      0.35      0.22       808\n",
      "          10       0.90      0.79      0.84     20427\n",
      "          11       0.32      0.38      0.35      2934\n",
      "\n",
      "   micro avg       0.70      0.61      0.65     81017\n",
      "   macro avg       0.53      0.50      0.51     81017\n",
      "weighted avg       0.72      0.61      0.66     81017\n",
      " samples avg       0.55      0.52      0.50     81017\n",
      "\n",
      "ABAW result: 1.359786, valence-arousal: 0.469121, expression: 0.383444, action unit: 0.507221\n"
     ]
    }
   ],
   "source": [
    "eval_ensemble(vaex_ensemble, val_features_, val_targets, val_targets_mask, print_f1_au_statistic=True,\n",
    "    print_f1_ex_statistic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6229bbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
