{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47a69e2",
   "metadata": {},
   "source": [
    "# useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "13ad3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose data type:\n",
      "0 - cropped, 1 - cropped_aligned\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('choose data type:\\n0 - cropped, 1 - cropped_aligned')\n",
    "choice = int(input())\n",
    "if choice not in [0, 1]:\n",
    "    print('error... value out of bounds...')\n",
    "else:\n",
    "    if not choice:\n",
    "        data_root = './cropped_data/cropped'\n",
    "        data_type = 'cropped'\n",
    "    else:\n",
    "        data_root = './cropped-aligned_data/cropped_aligned'\n",
    "        data_type = 'cropped-aligned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "7519f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!path \"./new_weights/cropped-aligned/batch=1024, logits=True/\" is already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_annotation_file = r'./annotations/training_set_annotations.txt'\n",
    "val_annotation_file = r'./annotations/validation_set_annotations.txt'\n",
    "model_path = r'./models/efficientnet_affectnet.pt'\n",
    "logits = True\n",
    "batch_size = 1024\n",
    "weights_dir = f'./new_weights/{data_type}/batch={batch_size}, logits={logits}/'\n",
    "\n",
    "if os.path.exists(weights_dir):\n",
    "    print(f'!path \"{weights_dir}\" is already exists')\n",
    "    pass\n",
    "else:\n",
    "    print(f'!path \"{weights_dir}\" was created')\n",
    "    os.mkdir(weights_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460ee4f",
   "metadata": {},
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "a26b6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.nn.functional as F\n",
    "from timm.loss import AsymmetricLossSingleLabel\n",
    "import facenet_pytorch\n",
    "from facenet_pytorch import MTCNN\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "from torchmetrics import HingeLoss, F1Score\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "3705bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected device is cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Connected device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "dbf3dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(1996)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9000d",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "c06e713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolvedSignMomentumOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr=1e-4, betas=(.9, .99), weight_decay=.0):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError('Invalid learning rate: {}'.format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError('Invalid beta parameter at index 0: {}'.format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError('Invalid beta parameter at index 1: {}'.format(betas[1]))\n",
    "        \n",
    "        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "            # Perform stepweight decay\n",
    "            p.data.mul_(1 - group['lr'] * group['weight_decay'])\n",
    "\n",
    "            grad = p.grad\n",
    "            state = self.state[p]\n",
    "            # State initialization\n",
    "            if len(state) == 0:\n",
    "              # Exponential moving average of gradient values\n",
    "              state['exp_avg'] = torch.zeros_like(p)\n",
    "\n",
    "            exp_avg = state['exp_avg']\n",
    "            beta1, beta2 = group['betas']\n",
    "\n",
    "            # Weight update\n",
    "            update = exp_avg * beta1 + grad * (1 - beta1)\n",
    "            p.add_(torch.sign(update), alpha=-group['lr'])\n",
    "            # Decay the momentum running average coefficient\n",
    "            exp_avg.mul_(beta2).add_(grad, alpha=1 - beta2)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "537cce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_CCC(prediction, ground_truth):\n",
    "    assert len(prediction) == len(ground_truth)\n",
    "    \n",
    "    eps = 1e-8\n",
    "    \n",
    "    n_objects = len(prediction)\n",
    "    ground_truth = ground_truth.view(-1)\n",
    "    prediction = prediction.view(-1)\n",
    "\n",
    "    prediction_mean = torch.sum(prediction) / n_objects\n",
    "    ground_truth_mean = torch.sum(ground_truth) / n_objects\n",
    "\n",
    "    prediction_var = (prediction - prediction_mean)\n",
    "    ground_truth_var = (ground_truth - ground_truth_mean)\n",
    "    \n",
    "    numerator = 2*torch.dot(prediction_var, ground_truth_var)\n",
    "    denominator = (torch.dot(prediction_var, prediction_var) + torch.dot(ground_truth_var, ground_truth_var) + torch.pow(prediction_mean - ground_truth_mean, 2) + eps)\n",
    "\n",
    "    ccc = numerator / denominator\n",
    "    \n",
    "    return ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "b10ee415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(prediction, ground_truth, task):\n",
    "    if task == 'VA':\n",
    "        CCC_va = compute_CCC(prediction[:, 0].to(device), ground_truth[:, 0].to(device))\n",
    "        CCC_ar = compute_CCC(prediction[:, 1].to(device), ground_truth[:, 1].to(device))   \n",
    "        \n",
    "        competition_part = 0.5 * (CCC_va + CCC_ar)\n",
    "    elif task == 'EX':\n",
    "        ground_truth = ground_truth.clone().cpu().detach().numpy()\n",
    "        prediction = prediction.clone().cpu().detach().numpy()\n",
    "        \n",
    "        competition_part = f1_score(ground_truth, prediction, average='macro')\n",
    "    elif task == 'AU':\n",
    "        ground_truth = ground_truth.clone().cpu().detach().numpy()\n",
    "        prediction = prediction.clone().cpu().detach().numpy()\n",
    "        \n",
    "        all_F1 = []\n",
    "        for t in range(12):\n",
    "            ground_truth_ = ground_truth[:, t]\n",
    "            prediction_ = prediction[:, t]\n",
    "            all_F1.append(f1_score(ground_truth_, prediction_, zero_division=0))\n",
    "\n",
    "        competition_part = np.mean(all_F1)\n",
    "\n",
    "    return competition_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "dd203c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABAWCCCLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ABAWCCCLoss, self).__init__()\n",
    "        self.eps = 1e-8\n",
    "\n",
    "    def forward(self, prediction, ground_truth):\n",
    "        assert len(prediction) == len(ground_truth)\n",
    "        \n",
    "        prediction_va, prediction_ar = prediction[:, 0], prediction[:, 1]\n",
    "        ground_truth_va, ground_truth_ar = ground_truth[:, 0], ground_truth[:, 1]\n",
    "        \n",
    "        CCC_va = compute_CCC(prediction_va, ground_truth_va)\n",
    "        CCC_ar = compute_CCC(prediction_ar, ground_truth_ar)\n",
    "        \n",
    "        loss = 1 - 0.5 * (CCC_va + CCC_ar)\n",
    "        loss.requires_grad_ = True\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "bcfe152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABAWMTLLoss(nn.Module):\n",
    "    def __init__(self, expression_weights, action_unit_weights):\n",
    "        super(ABAWMTLLoss, self).__init__()\n",
    "        self.va_criterion = ABAWCCCLoss()\n",
    "        self.ex_criterion = nn.CrossEntropyLoss(weight=expression_weights)\n",
    "        self.au_criterion = nn.BCEWithLogitsLoss(pos_weight=action_unit_weights.reshape(-1, 12))\n",
    "        \n",
    "    def forward(self, prediction, ground_truth):\n",
    "        assert len(prediction) == len(ground_truth)\n",
    "        va_input, ex_input, au_input = ground_truth[:, :2].to(device), \\\n",
    "            ground_truth[:, 3].to(device), ground_truth[:, 3:].to(device)\n",
    "        ex_input = ex_input.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        va_output, ex_output, au_output = ground_truth[:, :2].to(device), \\\n",
    "            prediction[:, 2:10].to(device), prediction[:, 10:].to(device)\n",
    "        \n",
    "        \n",
    "        va_loss = self.va_criterion(va_output, va_input)\n",
    "        ex_loss = self.ex_criterion(ex_output, ex_input)\n",
    "        au_loss = self.au_criterion(au_output, au_input)    \n",
    "        \n",
    "        total_loss = va_loss + ex_loss + au_loss\n",
    "        total_loss.requires_grad_ = True\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "78ec7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, train_dataloader, task, val_dataloader,\n",
    "                        current_weights_name, best_competition_part):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    number_of_objects = len(train_dataloader)\n",
    "    to_train = True\n",
    "    \n",
    "    for i, (extracted_features, ground_truth) in enumerate(tqdm(train_dataloader, 0)):\n",
    "        extracted_features, ground_truth = extracted_features.to(device), ground_truth.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if task == 'VA':\n",
    "            valence_output, arousal_output = model(extracted_features)\n",
    "            prediction = torch.concat((valence_output, arousal_output), dim=1)\n",
    "            prediction_ = prediction\n",
    "        elif task == 'EX':\n",
    "            ground_truth = ground_truth.unsqueeze(1).long()\n",
    "            prediction = model(extracted_features).unsqueeze(2)\n",
    "            _, prediction_ = torch.max(prediction.data, 1)\n",
    "        elif task == 'AU':\n",
    "            prediction = model(extracted_features)\n",
    "            prediction_ = ((prediction >= 0.5) * 1)\n",
    "        \n",
    "        iteration_loss = criterion(prediction, ground_truth)\n",
    "        iteration_loss.backward()\n",
    "        running_loss += iteration_loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i == 0:\n",
    "            epoch_prediction = prediction_\n",
    "            epoch_ground_truth = ground_truth\n",
    "        else:\n",
    "            epoch_prediction = torch.concat((epoch_prediction, prediction_), dim=0)\n",
    "            epoch_ground_truth = torch.concat((epoch_ground_truth, ground_truth), dim=0)\n",
    "        \n",
    "        _, iteration_competition_part = eval_one_epoch(model=model, criterion=criterion, \n",
    "            val_dataloader=val_dataloader, task=task, to_print=False)\n",
    "        \n",
    "        if iteration_competition_part > best_competition_part:\n",
    "            if current_weights_name == '':\n",
    "                pass\n",
    "            else:\n",
    "                os.remove(current_weights_name)\n",
    "            best_competition_part = iteration_competition_part\n",
    "            torch.save(model.state_dict(), weights_dir+f'{task}_{best_competition_part:3f}.pt')\n",
    "            current_weights_name = weights_dir+f'{task}_{best_competition_part:3f}.pt'\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'best {task} competition part = {best_competition_part:3f}, \\\n",
    "current {task} competition part = {iteration_competition_part:3f}')\n",
    "            \n",
    "    epoch_loss = running_loss / number_of_objects\n",
    "    competition_part = evaluate_model(epoch_prediction, epoch_ground_truth, task=task)\n",
    "    \n",
    "    print(f'train evaluations:')\n",
    "    print(f'task {task}: loss = {epoch_loss:3f}, {task} part = {competition_part:3f}')\n",
    "    \n",
    "    return current_weights_name, best_competition_part, to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "650a08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(model, criterion, val_dataloader, task, to_print=True):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    number_of_objects = len(val_dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (extracted_features, ground_truth) in enumerate(val_dataloader, 0):\n",
    "            extracted_features, ground_truth = extracted_features.to(device), ground_truth.to(device)\n",
    "\n",
    "            if task == 'VA':\n",
    "                valence_output, arousal_output = model(extracted_features)\n",
    "                prediction = torch.concat((valence_output, arousal_output), dim=1)\n",
    "                prediction_ = prediction\n",
    "            elif task == 'EX':\n",
    "                ground_truth = ground_truth.unsqueeze(1).long()\n",
    "                prediction = model(extracted_features).unsqueeze(2)\n",
    "                _, prediction_ = torch.max(prediction.data, 1)\n",
    "            elif task == 'AU':\n",
    "                prediction = model(extracted_features)\n",
    "                prediction_ = ((prediction >= 0.5) * 1)\n",
    "\n",
    "            iteration_loss = criterion(prediction, ground_truth)\n",
    "            running_loss += iteration_loss.item()\n",
    "\n",
    "            if i == 0:\n",
    "                epoch_prediction = prediction_\n",
    "                epoch_ground_truth = ground_truth\n",
    "            else:\n",
    "                epoch_prediction = torch.concat((epoch_prediction, prediction_), dim=0)\n",
    "                epoch_ground_truth = torch.concat((epoch_ground_truth, ground_truth), dim=0)\n",
    "            \n",
    "    epoch_loss = running_loss / number_of_objects\n",
    "    competition_part = evaluate_model(epoch_prediction, epoch_ground_truth, task=task)\n",
    "    \n",
    "    if to_print:\n",
    "        print(f'validation evaluations:')\n",
    "        print(f'task {task}: loss = {epoch_loss:3f}, {task} part = {competition_part:3f}')\n",
    "    \n",
    "    return epoch_loss, competition_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "d0d018aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emo_weights(y_train):\n",
    "    unique, counts = torch.unique(y_train, return_counts=True)\n",
    "    n_classes = len(unique)\n",
    "    class_weight = 1 / counts\n",
    "    class_weight /= class_weight.min()\n",
    "    class_weight = class_weight.to(device)\n",
    "    class_weight = class_weight.to(torch.float)\n",
    "\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "d0f560fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_unit_weights(targets):\n",
    "    action_unit_positive_weights = [1 / torch.sum(targets[:, i] == 1).item() * (targets.shape[0] / 2) for i in range(targets.shape[1])]\n",
    "    action_unit_negative_weights = [1 / torch.sum(targets[:, i] == 0).item() * (targets.shape[0] / 2) for i in range(targets.shape[1])]\n",
    "\n",
    "    action_unit_positive_weights = torch.tensor(data=action_unit_positive_weights,\n",
    "        dtype=torch.float, device=device).unsqueeze(1)\n",
    "    action_unit_negative_weights = torch.tensor(data=action_unit_negative_weights,\n",
    "        dtype=torch.float, device=device).unsqueeze(1)\n",
    "    action_units_weights = torch.concat((action_unit_negative_weights, action_unit_positive_weights), dim=1)\n",
    "    return action_unit_positive_weights.squeeze(0), action_unit_negative_weights.squeeze(0), action_units_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f866ec",
   "metadata": {},
   "source": [
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "4651a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "99854905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model (./models/efficientnet_affectnet.pt) was correctly load\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_weights = {}\n",
    "load = torch.load(model_path)\n",
    "\n",
    "weights = load.classifier.weight.cpu().data.numpy()\n",
    "bias = load.classifier.bias.cpu().data.numpy()\n",
    "model_weights['efficientnet_based'] = {'weights': weights, 'bias': bias}\n",
    "print(f'model ({model_path}) was correctly load\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b123db",
   "metadata": {},
   "source": [
    "$ features = Xw^{T} + b$ \\\n",
    "*Logit Function*:\n",
    "$ L = ln\\frac{p}{1 - p}$*, where* $p = \\frac{1}{1 + e^{-L}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "573b8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(features, classifier_weights, classifier_bias, logits=True):\n",
    "    xs = np.dot(features, np.transpose(classifier_weights)) + classifier_bias\n",
    "\n",
    "    if logits:\n",
    "        return xs\n",
    "    else:\n",
    "        e_x = np.exp(xs - np.max(xs, axis=1)[:,np.newaxis])\n",
    "        return e_x / e_x.sum(axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "e2b35da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_features(model_path):\n",
    "    global_features = []\n",
    "    images = []\n",
    "    images_names = []\n",
    "    feature_extractor_model = torch.load(model_path)\n",
    "    if isinstance(feature_extractor_model, dict):\n",
    "        if 'inception_resnet' in correct_path:\n",
    "            feature_extractor_model = facenet_pytorch.InceptionResnetV1(pretrained='vggface2')\n",
    "            feature_extractor_model.logits = torch.nn.Identity()\n",
    "            feature_extractor_model.last_bn = torch.nn.Identity()\n",
    "            feature_extractor_model.last_linear = torch.nn.Identity()\n",
    "\n",
    "        else:\n",
    "            print(\"!densenet doesn't match keys\")\n",
    "            return global_features, images_names\n",
    "    else:\n",
    "        feature_extractor_model.classifier = torch.nn.Identity()\n",
    "    feature_extractor_model.to(device)\n",
    "    feature_extractor_model.eval()\n",
    "    for dir in tqdm(os.listdir(data_root)):\n",
    "        frames_dir = os.path.join(data_root, dir)\n",
    "        for image_name in os.listdir(frames_dir):\n",
    "            image_name = os.path.join(frames_dir, image_name)\n",
    "            if image_name.lower().endswith('.jpg'):\n",
    "                image = Image.open(image_name)\n",
    "                image_tensor = transforms(image)\n",
    "                if image.size:\n",
    "                    images_names.append(image_name)\n",
    "                    images.append(image_tensor)\n",
    "                    if len(images) >= 64:\n",
    "                        with torch.no_grad():\n",
    "                            features = feature_extractor_model(torch.stack(images, dim=0).to(device))\n",
    "                        features = features.data.cpu().numpy()\n",
    "\n",
    "                        if len(global_features):\n",
    "                            global_features = np.concatenate((global_features, features), axis=0)\n",
    "                        else:\n",
    "                            global_features = features\n",
    "                        \n",
    "                        # reset images\n",
    "                        images.clear()\n",
    "                        \n",
    "    if len(images): # get all the remains\n",
    "        features = feature_extractor_model(torch.stack(images, dim=0).to(device))\n",
    "        features = features.data.cpu().numpy() \n",
    "\n",
    "    if len(global_features):\n",
    "        global_features = np.concatenate((global_features, features), axis=0)\n",
    "    else:\n",
    "        global_features = features \n",
    "\n",
    "    images.clear()\n",
    "    return global_features, images_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "3223c690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0947eec720c4cf59910e032bdc765d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_features, images_names = get_global_features(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "b8087630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!saving ./models/efficientnet_affectnet.pt features, scores and images_names, with logits=True\n"
     ]
    }
   ],
   "source": [
    "scores = get_prob(global_features, weights, bias, logits=logits)\n",
    "filename2featuresAll = {}\n",
    "print(f'!saving {model_path} features, scores and images_names, with logits={logits}')\n",
    "filename2featuresAll = {img_name:(global_feature,score) for img_name,global_feature,score in zip(images_names,global_features,scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "8c1df052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_target(annotation_file, filename2featuresAll):\n",
    "    with open(annotation_file) as f:\n",
    "        mtl_lines = f.read().splitlines()\n",
    "    n_missed=0\n",
    "    features, y_VA, y_EX, y_AU, y_AR = [], [], [], [], []\n",
    "    mask_VA, mask_EX, mask_AU, mask_AR = [], [], [], []\n",
    "    for line in mtl_lines[1:]:\n",
    "        target_values = line.split(',')\n",
    "        image_name = os.path.join(data_root, target_values[0].replace('/', '\\\\'))\n",
    "        image_name.replace('\\\\', '\\\\\\\\')\n",
    "        valence_value = float(target_values[1])\n",
    "        arousal_value = float(target_values[2])\n",
    "        expression_value = int(target_values[3])\n",
    "        au_values = [int(au_value) for au_value in target_values[4:]]\n",
    "        \n",
    "        VA_threshold = -5\n",
    "        EX_threshold = -1\n",
    "\n",
    "        mask_va = (valence_value > VA_threshold and arousal_value > VA_threshold)\n",
    "        if not mask_va:\n",
    "            valence_value = arousal_value = 0\n",
    "\n",
    "        # mask_ar = (arousal_value > VA_threshold)\n",
    "        # if not mask_ar:\n",
    "        #     arousal_value = 0\n",
    "        \n",
    "        mask_ex = (expression_value > EX_threshold)\n",
    "        if not mask_ex:\n",
    "            expression_value = 0\n",
    "            \n",
    "        mask_au = min(au_values) >= 0\n",
    "        if not mask_au:\n",
    "            au_values = [0]*len(au_values)\n",
    "\n",
    "        if mask_va or mask_ex or mask_au:\n",
    "            if image_name in filename2featuresAll:\n",
    "                features.append(np.concatenate((filename2featuresAll[image_name][0], \n",
    "                                                    filename2featuresAll[image_name][1])))\n",
    "                y_VA.append((valence_value, arousal_value))\n",
    "                mask_VA.append(mask_va)\n",
    "\n",
    "                # y_AR.append(arousal_value)\n",
    "                # mask_AR.append(mask_ar)\n",
    "                \n",
    "                y_EX.append(expression_value)\n",
    "                mask_EX.append(mask_ex)\n",
    "                \n",
    "                y_AU.append(au_values)\n",
    "                mask_AU.append(mask_au)\n",
    "            else:\n",
    "                n_missed+=1\n",
    "\n",
    "    features = np.array(features)\n",
    "    y_VA = np.array(y_VA)\n",
    "    # y_AR = np.array(y_AR)\n",
    "    y_EX = np.array(y_EX)\n",
    "    y_AU = np.array(y_AU)\n",
    "\n",
    "    mask_VA = np.array(mask_VA).astype(np.float32)\n",
    "    # mask_AR = np.array(mask_AR).astype(np.float32)\n",
    "    mask_EX = np.array(mask_EX).astype(np.float32)\n",
    "    mask_AU = np.array(mask_AU).astype(np.float32)\n",
    "\n",
    "    print(f'shapes:\\n\\\n",
    "            features = {features.shape}\\n\\\n",
    "            valence = {y_VA.shape}\\n\\\n",
    "            expression = {y_EX.shape}\\n\\\n",
    "            aus = {y_AU.shape}\\n')\n",
    "    \n",
    "    assert features.shape[0] == y_VA.shape[0] == y_EX.shape[0] == y_AU.shape[0]\n",
    "    print(f'assert passed...\\nnum_missed: {n_missed}')\n",
    "    \n",
    "    # return features, y_VA, y_EX, y_AU, mask_VA, mask_EX, mask_AU, y_AR, mask_AR\n",
    "    return features, y_VA, y_EX, y_AU, mask_VA, mask_EX, mask_AU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "2a06f3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes:\n",
      "            features = (142333, 1290)\n",
      "            valence = (142333, 2)\n",
      "            expression = (142333,)\n",
      "            aus = (142333, 12)\n",
      "\n",
      "assert passed...\n",
      "num_missed: 0\n",
      "shapes:\n",
      "            features = (26876, 1290)\n",
      "            valence = (26876, 2)\n",
      "            expression = (26876,)\n",
      "            aus = (26876, 12)\n",
      "\n",
      "assert passed...\n",
      "num_missed: 0\n"
     ]
    }
   ],
   "source": [
    "seed_everything(1996)\n",
    "\n",
    "train_features, train_y_VA, train_y_EX, train_y_AU, \\\n",
    "train_mask_VA,train_mask_EX, train_mask_AU = get_features_and_target(annotation_file=train_annotation_file, \n",
    "                                                                     filename2featuresAll=filename2featuresAll)\n",
    "\n",
    "val_features, val_y_VA, val_y_EX, val_y_AU, \\\n",
    "val_mask_VA, val_mask_EX, val_mask_AU = get_features_and_target(annotation_file=val_annotation_file, \n",
    "                                                                filename2featuresAll=filename2featuresAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "3e1d2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1996)\n",
    "\n",
    "X_VA_train, y_VA_train = torch.tensor(train_features[train_mask_VA == 1], dtype=torch.float32), torch.tensor(train_y_VA[train_mask_VA == 1], dtype=torch.float32)\n",
    "X_VA_val, y_VA_val = torch.tensor(val_features[val_mask_VA == 1], dtype=torch.float32), torch.tensor(val_y_VA[val_mask_VA == 1], dtype=torch.float32)\n",
    "\n",
    "VA_train_dataset = TensorDataset(X_VA_train, y_VA_train)\n",
    "VA_val_dataset = TensorDataset(X_VA_val, y_VA_val)\n",
    "\n",
    "VA_trainloader = DataLoader(VA_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "VA_valloader = DataLoader(VA_val_dataset, batch_size=len(X_VA_val), shuffle=False)\n",
    "\n",
    "X_EX_train, y_EX_train = torch.tensor(train_features[train_mask_EX == 1], dtype=torch.float32), torch.tensor(train_y_EX[train_mask_EX == 1], dtype=torch.float32)\n",
    "X_EX_val, y_EX_val = torch.tensor(val_features[val_mask_EX == 1], dtype=torch.float32), torch.tensor(val_y_EX[val_mask_EX == 1], dtype=torch.float32)\n",
    "\n",
    "EX_train_dataset = TensorDataset(X_EX_train, y_EX_train)\n",
    "EX_val_dataset = TensorDataset(X_EX_val, y_EX_val)\n",
    "\n",
    "EX_trainloader = DataLoader(EX_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "EX_valloader = DataLoader(EX_val_dataset, batch_size=len(X_EX_val), shuffle=False)\n",
    "\n",
    "X_AU_train, y_AU_train = torch.tensor(train_features[train_mask_AU == 1], dtype=torch.float32), torch.tensor(train_y_AU[train_mask_AU == 1], dtype=torch.float32)\n",
    "X_AU_val, y_AU_val = torch.tensor(val_features[val_mask_AU == 1], dtype=torch.float32), torch.tensor(val_y_AU[val_mask_AU == 1], dtype=torch.float32)\n",
    "\n",
    "AU_train_dataset = TensorDataset(X_AU_train, y_AU_train)\n",
    "AU_val_dataset = TensorDataset(X_AU_val, y_AU_val)\n",
    "\n",
    "AU_trainloader = DataLoader(AU_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "AU_valloader = DataLoader(AU_val_dataset, batch_size=len(X_AU_val), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "c95815cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of legit observations:\n",
      "train examples:\n",
      "valence-arousal features: 103917, valence-arousal targets: 103917\n",
      "expression features: 90645, expression targets: 90645\n",
      "action unit features: 103316, action unit targets: 103316\n",
      "\n",
      "validation examples:\n",
      "valence-arousal features: 26876, valence-arousal targets: 26876\n",
      "expression features: 15440, expression targets: 15440\n",
      "action unit features: 26876, action unit targets: 26876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'number of legit observations:\\n\\\n",
    "train examples:\\n\\\n",
    "valence-arousal features: {len(X_VA_train)}, valence-arousal targets: {len(y_VA_train)}\\n\\\n",
    "expression features: {len(X_EX_train)}, expression targets: {len(y_EX_train)}\\n\\\n",
    "action unit features: {len(X_AU_train)}, action unit targets: {len(y_AU_train)}\\n\\n\\\n",
    "validation examples:\\n\\\n",
    "valence-arousal features: {len(X_VA_val)}, valence-arousal targets: {len(y_VA_val)}\\n\\\n",
    "expression features: {len(X_EX_val)}, expression targets: {len(y_EX_val)}\\n\\\n",
    "action unit features: {len(X_AU_val)}, action unit targets: {len(y_AU_val)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb66b8",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "7c3ac3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class valence_arousal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.55)\n",
    "        \n",
    "        self.valence_head = nn.Linear(in_features=self.in_features, out_features=1)\n",
    "        self.arousal_head = nn.Linear(in_features=self.in_features, out_features=1)\n",
    "        \n",
    "        self.head_activation = nn.Tanh()\n",
    "    \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        valence_output = self.head_activation(self.valence_head(output))\n",
    "        arousal_output = self.head_activation(self.arousal_head(output))\n",
    "        \n",
    "        return valence_output, arousal_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "4e311e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class expression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "        self.expression_head = nn.Linear(in_features=self.in_features, out_features=8)\n",
    "        \n",
    "        self.head_activation = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        expression_output = self.head_activation(self.expression_head(output))\n",
    "        \n",
    "        return expression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "1fee3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class action_unit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_features = 1290\n",
    "        self.hidden = nn.Linear(in_features=self.in_features, out_features=self.in_features)\n",
    "        self.hidden_activation = nn.LeakyReLU()\n",
    "        self.hidden_batchnorm = nn.BatchNorm1d(num_features=self.in_features)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.6)\n",
    "        \n",
    "        self.action_unit_head = nn.Linear(in_features=self.in_features, out_features=12)\n",
    "        \n",
    "        self.head_activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, extracted_features):\n",
    "        output = self.hidden(extracted_features)\n",
    "        output = self.hidden_batchnorm(output)\n",
    "        output = self.hidden_activation(output)\n",
    "        output = self.hidden_dropout(output)\n",
    "        \n",
    "        action_unit_output = self.head_activation(self.action_unit_head(output))\n",
    "        \n",
    "        return action_unit_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "807541c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_model = valence_arousal().to(device)\n",
    "va_optimizer = torch.optim.Adam(va_model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "ex_model = expression().to(device)\n",
    "ex_optimizer = torch.optim.Adam(ex_model.parameters(), lr=1e-3)\n",
    "\n",
    "au_model = action_unit().to(device)\n",
    "au_optimizer = torch.optim.Adam(au_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728a803",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "1df40dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 5\n",
    "\n",
    "va_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(va_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "va_criterion = ABAWCCCLoss()\n",
    "\n",
    "ex_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(ex_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "emotion_weights = get_emo_weights(y_EX_train)\n",
    "ex_criterion = nn.CrossEntropyLoss(weight=emotion_weights)\n",
    "\n",
    "au_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(au_optimizer, mode='min', factor=0.1, \n",
    "    patience=1, threshold=0.002, threshold_mode='abs')\n",
    "action_unit_positive_weights, _, _ = get_action_unit_weights(y_AU_train)\n",
    "action_unit_positive_weights = action_unit_positive_weights.reshape(-1, 12)\n",
    "au_criterion = nn.BCEWithLogitsLoss(pos_weight=action_unit_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "618cc482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch №01 is currently running...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a104959f29e409dbc95f013196c7738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best VA competition part = 0.383667, current VA competition part = 0.383667\n",
      "best VA competition part = 0.448942, current VA competition part = 0.431498\n",
      "best VA competition part = 0.448942, current VA competition part = 0.438134\n",
      "best VA competition part = 0.449502, current VA competition part = 0.449502\n",
      "best VA competition part = 0.450414, current VA competition part = 0.448173\n",
      "best VA competition part = 0.452668, current VA competition part = 0.445496\n",
      "best VA competition part = 0.452668, current VA competition part = 0.447822\n",
      "best VA competition part = 0.452668, current VA competition part = 0.437389\n",
      "best VA competition part = 0.452668, current VA competition part = 0.431746\n",
      "best VA competition part = 0.452668, current VA competition part = 0.428898\n",
      "best VA competition part = 0.452668, current VA competition part = 0.435885\n",
      "train evaluations:\n",
      "task VA: loss = 0.366680, VA part = 0.602317\n",
      "validation evaluations:\n",
      "task VA: loss = 0.570505, VA part = 0.429495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04737c5cf84f4fbc865e638ddeed73d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best EX competition part = 0.280450, current EX competition part = 0.280450\n",
      "best EX competition part = 0.306750, current EX competition part = 0.277067\n",
      "best EX competition part = 0.306750, current EX competition part = 0.277511\n",
      "best EX competition part = 0.306750, current EX competition part = 0.283879\n",
      "best EX competition part = 0.306750, current EX competition part = 0.289590\n",
      "best EX competition part = 0.306750, current EX competition part = 0.297238\n",
      "best EX competition part = 0.308752, current EX competition part = 0.299692\n",
      "best EX competition part = 0.331549, current EX competition part = 0.331549\n",
      "best EX competition part = 0.348522, current EX competition part = 0.348291\n",
      "train evaluations:\n",
      "task EX: loss = 1.673839, EX part = 0.490229\n",
      "validation evaluations:\n",
      "task EX: loss = 1.874997, EX part = 0.339720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0623c203b874e5e885754da019c4625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best AU competition part = 0.400871, current AU competition part = 0.400871\n",
      "best AU competition part = 0.400871, current AU competition part = 0.184237\n",
      "best AU competition part = 0.400871, current AU competition part = 0.378086\n",
      "best AU competition part = 0.430365, current AU competition part = 0.427307\n",
      "best AU competition part = 0.440945, current AU competition part = 0.440945\n",
      "best AU competition part = 0.454118, current AU competition part = 0.453970\n",
      "best AU competition part = 0.454118, current AU competition part = 0.448671\n",
      "best AU competition part = 0.460713, current AU competition part = 0.460713\n",
      "best AU competition part = 0.460713, current AU competition part = 0.457411\n",
      "best AU competition part = 0.462804, current AU competition part = 0.462804\n",
      "best AU competition part = 0.470478, current AU competition part = 0.467367\n",
      "train evaluations:\n",
      "task AU: loss = 0.831324, AU part = 0.495207\n",
      "validation evaluations:\n",
      "task AU: loss = 0.835635, AU part = 0.467367\n",
      "task VA: previous lr: 0.001, scheduled lr: 0.001\n",
      "task EX: previous lr: 0.001, scheduled lr: 0.001\n",
      "task AU: previous lr: 0.001, scheduled lr: 0.001\n",
      "epoch №02 is currently running...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d3282dd84143e5bea668af3f347915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best VA competition part = 0.452668, current VA competition part = 0.432309\n",
      "best VA competition part = 0.452668, current VA competition part = 0.421477\n",
      "best VA competition part = 0.452668, current VA competition part = 0.416976\n",
      "best VA competition part = 0.452668, current VA competition part = 0.414198\n",
      "best VA competition part = 0.452668, current VA competition part = 0.408958\n",
      "best VA competition part = 0.452668, current VA competition part = 0.405787\n",
      "best VA competition part = 0.452668, current VA competition part = 0.407679\n",
      "best VA competition part = 0.452668, current VA competition part = 0.422362\n",
      "best VA competition part = 0.452668, current VA competition part = 0.406606\n",
      "best VA competition part = 0.452668, current VA competition part = 0.380651\n",
      "best VA competition part = 0.452668, current VA competition part = 0.396822\n",
      "train evaluations:\n",
      "task VA: loss = 0.251756, VA part = 0.737891\n",
      "validation evaluations:\n",
      "task VA: loss = 0.599327, VA part = 0.400673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fa8f03aac747d3a0ce0cc9ce37c7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best EX competition part = 0.362734, current EX competition part = 0.326468\n",
      "best EX competition part = 0.370579, current EX competition part = 0.348771\n",
      "best EX competition part = 0.370579, current EX competition part = 0.336514\n",
      "best EX competition part = 0.370579, current EX competition part = 0.316370\n",
      "best EX competition part = 0.370579, current EX competition part = 0.329923\n",
      "best EX competition part = 0.370579, current EX competition part = 0.290586\n",
      "best EX competition part = 0.370579, current EX competition part = 0.296069\n",
      "best EX competition part = 0.370579, current EX competition part = 0.311041\n",
      "best EX competition part = 0.370579, current EX competition part = 0.307063\n",
      "train evaluations:\n",
      "task EX: loss = 1.509728, EX part = 0.705245\n",
      "validation evaluations:\n",
      "task EX: loss = 1.961005, EX part = 0.307944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c5e2af335a4645878b5cf3f2999909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best AU competition part = 0.470478, current AU competition part = 0.470000\n",
      "best AU competition part = 0.475511, current AU competition part = 0.475089\n",
      "best AU competition part = 0.475997, current AU competition part = 0.471357\n",
      "best AU competition part = 0.480685, current AU competition part = 0.478383\n",
      "best AU competition part = 0.485111, current AU competition part = 0.485111\n",
      "best AU competition part = 0.490437, current AU competition part = 0.490437\n",
      "best AU competition part = 0.493470, current AU competition part = 0.487905\n",
      "best AU competition part = 0.494923, current AU competition part = 0.494923\n",
      "best AU competition part = 0.496067, current AU competition part = 0.479925\n",
      "best AU competition part = 0.496067, current AU competition part = 0.489582\n",
      "best AU competition part = 0.499508, current AU competition part = 0.499508\n",
      "train evaluations:\n",
      "task AU: loss = 0.797243, AU part = 0.614897\n",
      "validation evaluations:\n",
      "task AU: loss = 0.831146, AU part = 0.499508\n",
      "task VA: previous lr: 0.001, scheduled lr: 0.001\n",
      "task EX: previous lr: 0.001, scheduled lr: 0.001\n",
      "task AU: previous lr: 0.001, scheduled lr: 0.001\n",
      "epoch №03 is currently running...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db905fb903542e49c5f0488b2d5316d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best VA competition part = 0.452668, current VA competition part = 0.405243\n",
      "best VA competition part = 0.452668, current VA competition part = 0.388805\n",
      "best VA competition part = 0.452668, current VA competition part = 0.386890\n",
      "best VA competition part = 0.452668, current VA competition part = 0.386972\n",
      "best VA competition part = 0.452668, current VA competition part = 0.352212\n",
      "best VA competition part = 0.452668, current VA competition part = 0.375905\n",
      "best VA competition part = 0.452668, current VA competition part = 0.387777\n",
      "best VA competition part = 0.452668, current VA competition part = 0.392668\n",
      "best VA competition part = 0.452668, current VA competition part = 0.377049\n",
      "best VA competition part = 0.452668, current VA competition part = 0.360333\n",
      "best VA competition part = 0.452668, current VA competition part = 0.368321\n",
      "train evaluations:\n",
      "task VA: loss = 0.210749, VA part = 0.778404\n",
      "validation evaluations:\n",
      "task VA: loss = 0.600012, VA part = 0.399988\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c521352fb3d46df8d516b8dbb9ab07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best EX competition part = 0.370579, current EX competition part = 0.308600\n",
      "best EX competition part = 0.370579, current EX competition part = 0.294961\n",
      "best EX competition part = 0.370579, current EX competition part = 0.292502\n",
      "best EX competition part = 0.370579, current EX competition part = 0.304092\n",
      "best EX competition part = 0.370579, current EX competition part = 0.303165\n",
      "best EX competition part = 0.370579, current EX competition part = 0.314380\n",
      "best EX competition part = 0.370579, current EX competition part = 0.290767\n",
      "best EX competition part = 0.370579, current EX competition part = 0.270237\n",
      "best EX competition part = 0.370579, current EX competition part = 0.287233\n",
      "train evaluations:\n",
      "task EX: loss = 1.465052, EX part = 0.758937\n",
      "validation evaluations:\n",
      "task EX: loss = 1.965897, EX part = 0.283188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6cb8bae7d44052ac343927384c5d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best AU competition part = 0.499508, current AU competition part = 0.499080\n",
      "best AU competition part = 0.499508, current AU competition part = 0.494755\n",
      "best AU competition part = 0.499508, current AU competition part = 0.495782\n",
      "best AU competition part = 0.501110, current AU competition part = 0.499280\n",
      "best AU competition part = 0.501110, current AU competition part = 0.499898\n",
      "best AU competition part = 0.503229, current AU competition part = 0.498536\n",
      "best AU competition part = 0.503229, current AU competition part = 0.498553\n",
      "best AU competition part = 0.506116, current AU competition part = 0.506116\n",
      "best AU competition part = 0.507221, current AU competition part = 0.495368\n",
      "best AU competition part = 0.507221, current AU competition part = 0.495596\n",
      "best AU competition part = 0.507221, current AU competition part = 0.499915\n",
      "train evaluations:\n",
      "task AU: loss = 0.784202, AU part = 0.658899\n",
      "validation evaluations:\n",
      "task AU: loss = 0.829027, AU part = 0.499915\n",
      "task VA: previous lr: 0.001, scheduled lr: 0.0001\n",
      "task EX: previous lr: 0.001, scheduled lr: 0.0001\n",
      "task AU: previous lr: 0.001, scheduled lr: 0.0001\n",
      "epoch №04 is currently running...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6e8d12a21a43a587a0495734531e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best VA competition part = 0.452668, current VA competition part = 0.415475\n",
      "best VA competition part = 0.452668, current VA competition part = 0.371099\n",
      "best VA competition part = 0.452668, current VA competition part = 0.356474\n",
      "best VA competition part = 0.452668, current VA competition part = 0.375680\n",
      "best VA competition part = 0.452668, current VA competition part = 0.369454\n",
      "best VA competition part = 0.452668, current VA competition part = 0.363666\n",
      "best VA competition part = 0.452668, current VA competition part = 0.369973\n",
      "best VA competition part = 0.452668, current VA competition part = 0.363747\n",
      "best VA competition part = 0.452668, current VA competition part = 0.368126\n",
      "best VA competition part = 0.452668, current VA competition part = 0.375785\n",
      "best VA competition part = 0.452668, current VA competition part = 0.362874\n",
      "train evaluations:\n",
      "task VA: loss = 0.174871, VA part = 0.813448\n",
      "validation evaluations:\n",
      "task VA: loss = 0.638346, VA part = 0.361654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5561cf491e4b09a1ee7129749e650d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best EX competition part = 0.370579, current EX competition part = 0.282524\n",
      "best EX competition part = 0.370579, current EX competition part = 0.277266\n",
      "best EX competition part = 0.370579, current EX competition part = 0.280167\n",
      "best EX competition part = 0.370579, current EX competition part = 0.280637\n",
      "best EX competition part = 0.370579, current EX competition part = 0.285125\n",
      "best EX competition part = 0.370579, current EX competition part = 0.291053\n",
      "best EX competition part = 0.370579, current EX competition part = 0.290977\n",
      "best EX competition part = 0.370579, current EX competition part = 0.288615\n",
      "best EX competition part = 0.370579, current EX competition part = 0.285847\n",
      "train evaluations:\n",
      "task EX: loss = 1.440569, EX part = 0.788304\n",
      "validation evaluations:\n",
      "task EX: loss = 1.989610, EX part = 0.283097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a631f5307c47479aa774f081c6b5b0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best AU competition part = 0.507221, current AU competition part = 0.501159\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501002\n",
      "best AU competition part = 0.507221, current AU competition part = 0.500481\n",
      "best AU competition part = 0.507221, current AU competition part = 0.500105\n",
      "best AU competition part = 0.507221, current AU competition part = 0.500718\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501275\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501812\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501075\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501220\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501448\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501360\n",
      "train evaluations:\n",
      "task AU: loss = 0.778160, AU part = 0.680440\n",
      "validation evaluations:\n",
      "task AU: loss = 0.828785, AU part = 0.501360\n",
      "task VA: previous lr: 0.0001, scheduled lr: 0.0001\n",
      "task EX: previous lr: 0.0001, scheduled lr: 0.0001\n",
      "task AU: previous lr: 0.0001, scheduled lr: 0.0001\n",
      "epoch №05 is currently running...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724c277b7288403386e48b18f4e28def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best VA competition part = 0.452668, current VA competition part = 0.379623\n",
      "best VA competition part = 0.452668, current VA competition part = 0.339163\n",
      "best VA competition part = 0.452668, current VA competition part = 0.371320\n",
      "best VA competition part = 0.452668, current VA competition part = 0.352475\n",
      "best VA competition part = 0.452668, current VA competition part = 0.347223\n",
      "best VA competition part = 0.452668, current VA competition part = 0.356401\n",
      "best VA competition part = 0.452668, current VA competition part = 0.355905\n",
      "best VA competition part = 0.452668, current VA competition part = 0.366366\n",
      "best VA competition part = 0.452668, current VA competition part = 0.356482\n",
      "best VA competition part = 0.452668, current VA competition part = 0.365376\n",
      "best VA competition part = 0.452668, current VA competition part = 0.355068\n",
      "train evaluations:\n",
      "task VA: loss = 0.165907, VA part = 0.823036\n",
      "validation evaluations:\n",
      "task VA: loss = 0.645507, VA part = 0.354493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3206347fe0254548af026415bfba4af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best EX competition part = 0.370579, current EX competition part = 0.284070\n",
      "best EX competition part = 0.370579, current EX competition part = 0.284356\n",
      "best EX competition part = 0.370579, current EX competition part = 0.287384\n",
      "best EX competition part = 0.370579, current EX competition part = 0.286992\n",
      "best EX competition part = 0.370579, current EX competition part = 0.284786\n",
      "best EX competition part = 0.370579, current EX competition part = 0.285098\n",
      "best EX competition part = 0.370579, current EX competition part = 0.284891\n",
      "best EX competition part = 0.370579, current EX competition part = 0.285968\n",
      "best EX competition part = 0.370579, current EX competition part = 0.284878\n",
      "train evaluations:\n",
      "task EX: loss = 1.435543, EX part = 0.796717\n",
      "validation evaluations:\n",
      "task EX: loss = 1.991687, EX part = 0.280466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b2e11e93c845c89831ff65630d9067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best AU competition part = 0.507221, current AU competition part = 0.501193\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501724\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501243\n",
      "best AU competition part = 0.507221, current AU competition part = 0.503440\n",
      "best AU competition part = 0.507221, current AU competition part = 0.500900\n",
      "best AU competition part = 0.507221, current AU competition part = 0.500335\n",
      "best AU competition part = 0.507221, current AU competition part = 0.502491\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501640\n",
      "best AU competition part = 0.507221, current AU competition part = 0.499949\n",
      "best AU competition part = 0.507221, current AU competition part = 0.500758\n",
      "best AU competition part = 0.507221, current AU competition part = 0.501917\n",
      "train evaluations:\n",
      "task AU: loss = 0.777081, AU part = 0.683839\n",
      "validation evaluations:\n",
      "task AU: loss = 0.828503, AU part = 0.501917\n",
      "task VA: previous lr: 0.0001, scheduled lr: 1e-05\n",
      "task EX: previous lr: 0.0001, scheduled lr: 1e-05\n",
      "task AU: previous lr: 0.0001, scheduled lr: 1e-05\n"
     ]
    }
   ],
   "source": [
    "current_va_weights_name = ''\n",
    "current_ex_weights_name = ''\n",
    "current_au_weights_name = ''\n",
    "\n",
    "best_competition_part_va = 0\n",
    "best_competition_part_ex = 0\n",
    "best_competition_part_au = 0\n",
    "\n",
    "train_va = True\n",
    "train_ex = True\n",
    "train_au = True\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    if epoch in range(9):\n",
    "        print(f'epoch №0{epoch+1} is currently running...')\n",
    "    else:\n",
    "        print(f'epoch №{epoch+1} is currently running...')\n",
    "    \n",
    "    # VALENCE-AROUSAL\n",
    "    if train_va:\n",
    "        current_va_weights_name, best_competition_part_va, train_va = train_one_epoch(model=va_model, \n",
    "            criterion=va_criterion, optimizer=va_optimizer, train_dataloader=VA_trainloader, \n",
    "            val_dataloader=VA_valloader, task='VA', current_weights_name=current_va_weights_name, \n",
    "            best_competition_part=best_competition_part_va)\n",
    "        va_eval_loss, _ = eval_one_epoch(model=va_model, criterion=va_criterion, val_dataloader=VA_valloader, task='VA')\n",
    "\n",
    "        previous_va_lr = va_optimizer.param_groups[0]['lr']\n",
    "        va_scheduler.step(va_eval_loss)\n",
    "    \n",
    "    # EXPRESSION\n",
    "    if train_ex:\n",
    "        current_ex_weights_name, best_competition_part_ex, train_ex = train_one_epoch(model=ex_model, \n",
    "            criterion=ex_criterion, optimizer=ex_optimizer, train_dataloader=EX_trainloader, \n",
    "            val_dataloader=EX_valloader, task='EX', current_weights_name=current_ex_weights_name, \n",
    "            best_competition_part=best_competition_part_ex)\n",
    "        ex_eval_loss, _ = eval_one_epoch(model=ex_model, criterion=ex_criterion, val_dataloader=EX_valloader, task='EX')\n",
    "\n",
    "        previous_ex_lr = ex_optimizer.param_groups[0]['lr']\n",
    "        ex_scheduler.step(ex_eval_loss)\n",
    "    \n",
    "    # ACTION UNIT\n",
    "    if train_au:\n",
    "        current_au_weights_name, best_competition_part_au, train_au = train_one_epoch(model=au_model, \n",
    "            criterion=au_criterion, optimizer=au_optimizer, train_dataloader=AU_trainloader, \n",
    "            val_dataloader=AU_valloader, task='AU', current_weights_name=current_au_weights_name, \n",
    "            best_competition_part=best_competition_part_au)\n",
    "        au_eval_loss, _ = eval_one_epoch(model=au_model, criterion=au_criterion, val_dataloader=AU_valloader, task='AU')\n",
    "\n",
    "        previous_au_lr = au_optimizer.param_groups[0]['lr']\n",
    "        au_scheduler.step(ex_eval_loss)\n",
    "    \n",
    "    # LEARNING RATE DECREASE\n",
    "    print(f'task VA: previous lr: {previous_va_lr}, scheduled lr: {va_optimizer.param_groups[0][\"lr\"]}')\n",
    "    print(f'task EX: previous lr: {previous_ex_lr}, scheduled lr: {ex_optimizer.param_groups[0][\"lr\"]}')\n",
    "    print(f'task AU: previous lr: {previous_au_lr}, scheduled lr: {au_optimizer.param_groups[0][\"lr\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb87ca4",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "f0731204",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensemble(nn.Module):\n",
    "    def __init__(self, model_va, model_ex, model_au):\n",
    "        super().__init__()\n",
    "        self.model_va = model_va\n",
    "        self.model_ex = model_ex\n",
    "        self.model_au = model_au\n",
    "        \n",
    "        self.model_va.eval()\n",
    "        self.model_ex.eval()\n",
    "        self.model_au.eval()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            va_output, ar_output = self.model_va(x)\n",
    "            ex_output = self.model_ex(x)\n",
    "            au_output = self.model_au(x)\n",
    "\n",
    "        return va_output, ar_output, ex_output, au_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "ce5a203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ensemble(ensemble, val_features, val_targets, val_targets_mask):\n",
    "    with torch.no_grad():\n",
    "        va_output, ar_output, ex_output, au_output = ensemble(val_features)\n",
    "\n",
    "        va_input = val_targets[0][val_targets_mask[0] == 1]\n",
    "        va_output = torch.concat((va_output, ar_output), dim=1)\n",
    "        \n",
    "        va_competition_part = evaluate_model(va_output, va_input, task='VA')\n",
    "        \n",
    "        ex_input = val_targets[1][val_targets_mask[1] == 1].unsqueeze(1).long()\n",
    "        ex_output = ex_output.unsqueeze(2)\n",
    "        _, ex_output = torch.max(ex_output.data, 1)\n",
    "        ex_output = ex_output[val_targets_mask[1] == 1]\n",
    "        \n",
    "        ex_competition_part = evaluate_model(ex_output, ex_input, task='EX')\n",
    "\n",
    "        au_input = val_targets[2][val_targets_mask[2] == 1]\n",
    "        au_output = ((au_output >= 0.5) * 1)\n",
    "        au_output = au_output[val_targets_mask[2] == 1]\n",
    "        \n",
    "        au_competition_part = evaluate_model(au_output, au_input, task='AU')\n",
    "\n",
    "        abaw_metric = va_competition_part + ex_competition_part + au_competition_part\n",
    "        \n",
    "    print(f'ABAW result: {abaw_metric:3f}, valence-arousal: {va_competition_part:3f}, \\\n",
    "expression: {ex_competition_part:3f}, action unit: {au_competition_part:3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "13c9b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1996)\n",
    "\n",
    "val_features_ = torch.tensor(data=val_features, dtype=torch.float, device=device)\n",
    "val_targets = [torch.tensor(data=data, dtype=torch.float, device=device) for data in [val_y_VA, val_y_EX, val_y_AU]]\n",
    "val_targets_mask = [val_mask_VA, val_mask_EX, val_mask_AU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "b42203d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current valence-arousal weights path: \"./new_weights/cropped-aligned/batch=1024, logits=True/VA_0.452668.pt\",\n",
      "current expression weights path: \"./new_weights/cropped-aligned/batch=1024, logits=True/EX_0.370579.pt\",\n",
      "current action_unit weights path: \"./new_weights/cropped-aligned/batch=1024, logits=True/AU_0.507221.pt\",\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'current valence-arousal weights path: \"{current_va_weights_name}\",\\n\\\n",
    "current expression weights path: \"{current_ex_weights_name}\",\\n\\\n",
    "current action_unit weights path: \"{current_au_weights_name}\",\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "543ca2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_arousal_model = valence_arousal().to(device).eval()\n",
    "valence_arousal_model.load_state_dict(torch.load(current_va_weights_name))\n",
    "\n",
    "expression_model = expression().to(device).eval()\n",
    "expression_model.load_state_dict(torch.load(current_ex_weights_name))\n",
    "\n",
    "action_unit_model = action_unit().to(device).eval()\n",
    "action_unit_model.load_state_dict(torch.load(current_au_weights_name))\n",
    "\n",
    "ensemble = ensemble(model_va=valence_arousal_model, model_ex=expression_model, model_au=action_unit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "c20c2a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABAW result: 1.330468, valence-arousal: 0.452668, expression: 0.370579, action unit: 0.507221\n"
     ]
    }
   ],
   "source": [
    "eval_ensemble(ensemble, val_features_, val_targets, val_targets_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b287008",
   "metadata": {},
   "source": [
    "# best weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "7670bcca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "13\n",
      "best VA weights: ./new_weights/cropped-aligned/batch=1024, logits=True/VA_0.469680.pt,\n",
      "best EX weights: ./new_weights/cropped-aligned/batch=1024, logits=True/EX_0.370579.pt\n",
      "best AU weights: ./new_weights/cropped-aligned/batch=1024, logits=True/AU_0.507221.pt\n"
     ]
    }
   ],
   "source": [
    "all_va_weights = [weights_dir+weights for weights in os.listdir(weights_dir) if 'VA' in weights]\n",
    "all_ex_weights = [weights_dir+weights for weights in os.listdir(weights_dir) if 'EX' in weights]\n",
    "all_au_weights = [weights_dir+weights for weights in os.listdir(weights_dir) if 'AU' in weights]\n",
    "\n",
    "max_va_part = 0\n",
    "max_ex_part = 0\n",
    "max_au_part = 0\n",
    "\n",
    "best_va_weight = ''\n",
    "best_ex_weight = ''\n",
    "best_au_weight = ''\n",
    "\n",
    "print(len(all_ex_weights))\n",
    "print(len(all_va_weights))\n",
    "print(len(all_au_weights))\n",
    "\n",
    "\n",
    "for va_weight, ex_weight, au_weight in zip(all_va_weights, all_ex_weights, all_au_weights):\n",
    "    va_part = float(va_weight.split('_')[-1].split('.pt')[0])\n",
    "    ex_part = float(ex_weight.split('_')[-1].split('.pt')[0])\n",
    "    au_part = float(au_weight.split('_')[-1].split('.pt')[0])\n",
    "    \n",
    "    if va_part > max_va_part:\n",
    "        max_va_part = va_part\n",
    "        best_va_weight = va_weight\n",
    "    if ex_part > max_ex_part:\n",
    "        max_ex_part = ex_part\n",
    "        best_ex_weight = ex_weight\n",
    "    if au_part > max_au_part:\n",
    "        max_au_part = au_part\n",
    "        best_au_weight = au_weight\n",
    "\n",
    "print(f'best VA weights: {best_va_weight},\\n\\\n",
    "best EX weights: {best_ex_weight}\\n\\\n",
    "best AU weights: {best_au_weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "7d2858ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_arousal_model = valence_arousal().to(device)\n",
    "valence_arousal_model.load_state_dict(torch.load(best_va_weight))\n",
    "\n",
    "expression_model = expression().to(device)\n",
    "expression_model.load_state_dict(torch.load(best_ex_weight))\n",
    "\n",
    "action_unit_model = action_unit().to(device)\n",
    "action_unit_model.load_state_dict(torch.load(best_au_weight))\n",
    "\n",
    "best_ensemble = ensemble(model_va=valence_arousal_model, model_ex=expression_model, model_au=action_unit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "c9ded811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABAW result: 1.346921, valence-arousal: 0.469121, expression: 0.370579, action unit: 0.507221\n"
     ]
    }
   ],
   "source": [
    "eval_ensemble(best_ensemble, val_features_, val_targets, val_targets_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "1ed3b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_ensemble.state_dict(), weights_dir+f'best_ensemble.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7239c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
